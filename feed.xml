<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ssolllll.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ssolllll.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-16T09:55:00+00:00</updated><id>https://ssolllll.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">[Transformers] íŒŒì´í† ì¹˜ ë£¨í”„ íƒˆì¶œ: Trainer API 200% í™œìš© ê°€ì´ë“œ</title><link href="https://ssolllll.github.io/blog/2025/transformers-api/" rel="alternate" type="text/html" title="[Transformers] íŒŒì´í† ì¹˜ ë£¨í”„ íƒˆì¶œ: Trainer API 200% í™œìš© ê°€ì´ë“œ"/><published>2025-12-13T10:00:00+00:00</published><updated>2025-12-13T10:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/transformers-api</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/transformers-api/"><![CDATA[<p>ë”¥ëŸ¬ë‹ ëª¨ë¸ë§ì„ ì²˜ìŒ ë°°ìš¸ ë•ŒëŠ” <code class="language-plaintext highlighter-rouge">for epoch in epochs:</code> ë¡œ ì‹œì‘í•˜ëŠ” PyTorchì˜ Raw Loopë¥¼ ì§ì ‘ ì§œëŠ” ê²ƒì´ ê³µë¶€ì— ë„ì›€ì´ ëœë‹¤. í•˜ì§€ë§Œ <strong>ìƒìš© ìˆ˜ì¤€ì˜ LLM í•™ìŠµ íŒŒì´í”„ë¼ì¸</strong>ì„ êµ¬ì¶•í•  ë•Œ ì´ ë°©ì‹ì€ â€˜ê¸°ìˆ  ë¶€ì±„(Technical Debt)â€™ê°€ ë˜ê¸° ì‰½ë‹¤.</p> <p>Mixed Precision(fp16), Gradient Accumulation, Multi-GPU ë¶„ì‚° í•™ìŠµ(DDP), Logging, Checkpointing ê¸°ëŠ¥ì„ ë§¤ë²ˆ ì§ì ‘ êµ¬í˜„í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë‹¤.</p> <p>ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” Hugging Faceì˜ <code class="language-plaintext highlighter-rouge">Trainer</code> APIë¥¼ ë‹¨ìˆœí•œ í¸ì˜ ë„êµ¬ê°€ ì•„ë‹Œ, <strong>ê²¬ê³ í•œ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì˜ í‘œì¤€ ê·œê²©</strong>ìœ¼ë¡œ í™œìš©í•˜ëŠ” ì—”ì§€ë‹ˆì–´ë§ íŒì„ ê³µìœ í•œë‹¤.</p> <hr/> <h2 id="1-trainer-boilerplate-code-ì œê±°ì™€-í‘œì¤€í™”">1. Trainer: Boilerplate Code ì œê±°ì™€ í‘œì¤€í™”</h2> <p><code class="language-plaintext highlighter-rouge">Trainer</code> í´ë˜ìŠ¤ëŠ” í•™ìŠµì— í•„ìš”í•œ ëª¨ë“  Best Practiceê°€ ì§‘ì•½ë˜ì–´ ìˆë‹¤.</p> <h3 id="-bad-practice-raw-pytorch-loop">ğŸ”´ Bad Practice: Raw PyTorch Loop</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ë§¤ í”„ë¡œì íŠ¸ë§ˆë‹¤ ë°˜ë³µë˜ëŠ” ì§€ë£¨í•œ ì½”ë“œ...
</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="nc">GradScaler</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span>
    <span class="n">scaler</span><span class="p">.</span><span class="nf">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">).</span><span class="nf">backward</span><span class="p">()</span>  <span class="c1"># fp16 ì²˜ë¦¬
</span>    
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># ê·¸ë¼ë””ì–¸íŠ¸ ëˆ„ì  ì²˜ë¦¬
</span>        <span class="n">scaler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">scaler</span><span class="p">.</span><span class="nf">update</span><span class="p">()</span>
    
    <span class="c1"># ë¡œê¹…, ì²´í¬í¬ì¸íŠ¸ ì €ì¥, ê²€ì¦ ë¡œì§ ë“± ìˆ˜ë°± ì¤„ ì¶”ê°€ í•„ìš”
</span></code></pre></div></div> <h3 id="-best-practice-trainingarguments-í™œìš©">ğŸŸ¢ Best Practice: TrainingArguments í™œìš©</h3> <p><code class="language-plaintext highlighter-rouge">TrainingArguments</code>ì— ì„¤ì •ê°’ë§Œ ë„˜ê¸°ë©´ ë³µì¡í•œ ê¸°ëŠ¥ë“¤ì´ ë‚´ë¶€ì ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ì‹¤í–‰ëœë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>

<span class="n">args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">./results</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="c1"># ë°°ì¹˜ í¬ê¸° 16 íš¨ê³¼
</span>    <span class="n">fp16</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>                     <span class="c1"># Mixed Precision ìë™ ì ìš©
</span>    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">report_to</span><span class="o">=</span><span class="sh">"</span><span class="s">wandb</span><span class="sh">"</span><span class="p">,</span>             <span class="c1"># WandB, MLflow ìë™ ì—°ë™
</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="c1"># ...
</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p><strong>Engineering Note:</strong> íŒ€ ë‚´ì—ì„œ <code class="language-plaintext highlighter-rouge">TrainingArguments</code> ì„¤ì •ì„ ê³µìœ í•˜ë©´, ëˆ„ê°€ í•™ìŠµ ì½”ë“œë¥¼ ì§œë”ë¼ë„ ë™ì¼í•œ ë¡œê¹… í¬ë§·ê³¼ ì €ì¥ êµ¬ì¡°ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆì–´ í˜‘ì—… íš¨ìœ¨ì´ ê·¹ëŒ€í™”ëœë‹¤.</p> </blockquote> <hr/> <h2 id="2-callback-í•™ìŠµ-ì¤‘ê°„ì—-ê°œì…í•˜ê¸°-hooking">2. Callback: í•™ìŠµ ì¤‘ê°„ì— ê°œì…í•˜ê¸° (Hooking)</h2> <p><code class="language-plaintext highlighter-rouge">Trainer</code>ë¥¼ ì“°ë©´ ë‚´ë¶€ ë¡œì§ì„ ìˆ˜ì •í•˜ê¸° ì–´ë µë‹¤ê³  ìƒê°í•˜ê¸° ì‰½ë‹¤. í•˜ì§€ë§Œ <code class="language-plaintext highlighter-rouge">TrainerCallback</code>ì„ ì‚¬ìš©í•˜ë©´ <strong>í•™ìŠµì˜ íŠ¹ì • ì‹œì (Start, Step End, Epoch End ë“±)</strong>ì— ì›í•˜ëŠ” ì½”ë“œë¥¼ ì£¼ì…(Hook)í•  ìˆ˜ ìˆë‹¤.</p> <p>LLM í•™ìŠµ ì‹œ ê°€ì¥ ìœ ìš©í•œ ê²ƒì€ <strong>â€œLossë§Œ ë³´ì§€ ë§ê³ , ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì˜ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒâ€</strong>ì´ë‹¤.</p> <h3 id="-best-practice-ì‹¤ì‹œê°„-ìƒì„±-í‰ê°€-callback">ğŸŸ¢ Best Practice: ì‹¤ì‹œê°„ ìƒì„± í‰ê°€ Callback</h3> <p>í•™ìŠµ ë„ì¤‘(ì˜ˆ: ë§¤ 500 step ë§ˆë‹¤) ëª¨ë¸ì´ ë©ì²­í•œ ì†Œë¦¬ë¥¼ í•˜ê³  ìˆì§„ ì•Šì€ì§€ ìƒ˜í”Œì„ ìƒì„±í•´ì„œ ë¡œê·¸ì— ì°ì–´ë³´ëŠ” ì½œë°±ì´ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">TrainerCallback</span>

<span class="k">class</span> <span class="nc">GenerationCallback</span><span class="p">(</span><span class="n">TrainerCallback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">prompt_text</span><span class="o">=</span><span class="sh">"</span><span class="s">User: ì•ˆë…•?</span><span class="se">\n</span><span class="s">Assistant:</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">self</span><span class="p">.</span><span class="n">prompt_text</span> <span class="o">=</span> <span class="n">prompt_text</span>

    <span class="k">def</span> <span class="nf">on_step_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># 500 ìŠ¤í…ë§ˆë‹¤ ì‹¤í–‰
</span>        <span class="k">if</span> <span class="n">state</span><span class="p">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tokenizer</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">prompt_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            
            <span class="c1"># í•™ìŠµ ëª¨ë“œ(train) -&gt; í‰ê°€ ëª¨ë“œ(eval)ë¡œ ì ì‹œ ì „í™˜
</span>            <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
                <span class="n">generated_text</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">[Step </span><span class="si">{</span><span class="n">state</span><span class="p">.</span><span class="n">global_step</span><span class="si">}</span><span class="s">] Sample:</span><span class="se">\n</span><span class="si">{</span><span class="n">generated_text</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># ë‹¤ì‹œ í•™ìŠµ ëª¨ë“œë¡œ ë³µê·€
</span>            <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

<span class="c1"># Trainerì— ë“±ë¡
</span><span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="p">...,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="nc">GenerationCallback</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)]</span>
<span class="p">)</span>
</code></pre></div></div> <p>ì´ ì½œë°±ì´ ìˆìœ¼ë©´ í•™ìŠµì´ ì‚°ìœ¼ë¡œ ê°€ê³  ìˆëŠ”ì§€(Overfitting/Collapse)ë¥¼ Loss ê·¸ë˜í”„ë³´ë‹¤ í›¨ì”¬ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.</p> <hr/> <h2 id="3-storage-management-ë””ìŠ¤í¬-í­ë°œ-ë°©ì§€">3. Storage Management: ë””ìŠ¤í¬ í­ë°œ ë°©ì§€</h2> <p>LLM ì²´í¬í¬ì¸íŠ¸(Checkpoint)ëŠ” ê°œë‹¹ ìˆ˜ì‹­ GBì— ë‹¬í•œë‹¤. ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë‘ë©´ ë§¤ <code class="language-plaintext highlighter-rouge">save_steps</code> ë§ˆë‹¤ ì €ì¥ì´ ë˜ì–´ ê¸ˆì„¸ ë””ìŠ¤í¬ê°€ ê°€ë“ ì°¬ë‹¤.</p> <h3 id="-best-practice-save_total_limit--load_best_model_at_end">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">save_total_limit</code> &amp; <code class="language-plaintext highlighter-rouge">load_best_model_at_end</code></h3> <p>ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ í•˜ë‚˜ì™€, í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë‹¨ì„ ëŒ€ë¹„í•œ ìµœì‹  ëª¨ë¸ í•˜ë‚˜ë§Œ ë‚¨ê¸°ëŠ” ì „ëµì´ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">./llm-checkpoints</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    
    <span class="c1"># í•µì‹¬ ì˜µì…˜:
</span>    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>          <span class="c1"># ê°€ì¥ ìµœê·¼ 2ê°œë§Œ ë‚¨ê¸°ê³  ìë™ ì‚­ì œ
</span>    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># í•™ìŠµ ì¢…ë£Œ ì‹œ validation lossê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸ ë¡œë“œ
</span>    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span>
<span class="p">)</span>
</code></pre></div></div> <p>ì´ ì„¤ì •ì„ í†µí•´ ë””ìŠ¤í¬ ìš©ëŸ‰ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ë©´ì„œë„, í•™ìŠµì´ ì¤‘ê°„ì— ë©ˆì·„ì„ ë•Œ <code class="language-plaintext highlighter-rouge">trainer.train(resume_from_checkpoint=True)</code>ë¥¼ í†µí•´ ì–¸ì œë“  ì¬ê°œí•  ìˆ˜ ìˆëŠ” ì•ˆì „ì¥ì¹˜ë¥¼ ë§ˆë ¨í•  ìˆ˜ ìˆë‹¤.</p> <hr/> <h2 id="ê²°ë¡ ">ê²°ë¡ </h2> <p><code class="language-plaintext highlighter-rouge">Trainer</code> APIë¥¼ ì˜ ì“´ë‹¤ëŠ” ê²ƒì€ ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ë„˜ì–´, <strong>ì‹¤í—˜ì˜ ì¬í˜„ì„±(Reproducibility)</strong>ê³¼ <strong>ìš´ì˜ì˜ ì•ˆì •ì„±(Stability)</strong>ì„ í™•ë³´í•œë‹¤ëŠ” ì˜ë¯¸ë‹¤.</p> <ol> <li><strong>Arguments:</strong> ë³µì¡í•œ í•™ìŠµ ì„¤ì •ì„ dataclass í•˜ë‚˜ë¡œ ê´€ë¦¬.</li> <li><strong>Callback:</strong> í•™ìŠµ ê³¼ì •ì— ìœ ì—°í•˜ê²Œ ê°œì…í•˜ì—¬ Custom Logic ì‹¤í–‰.</li> <li><strong>Checkpointing:</strong> ë””ìŠ¤í¬ ìš©ëŸ‰ ê´€ë¦¬ ìë™í™”.</li> </ol> <p>ì´ì œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” íŒŒì´í”„ë¼ì¸ê¹Œì§€ êµ¬ì¶•í–ˆë‹¤. ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” í•™ìŠµëœ ê±°ëŒ€ ëª¨ë¸ì„ ë” ì‘ê³  ë¹ ë¥´ê²Œ ë§Œë“œëŠ” <strong>â€œ5. Optimization: ì–‘ìí™”(Quantization)ì™€ íš¨ìœ¨í™” ê¸°ë²•â€</strong>ì´ë‹¤. ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ ì‹œë¦¬ì¦ˆë¥¼ ë§ˆë¬´ë¦¬í•´ë³´ì.</p>]]></content><author><name></name></author><category term="engineering"/><category term="python"/><category term="transformers"/><category term="training"/><category term="mlops"/><category term="backend"/><summary type="html"><![CDATA[Raw PyTorch Loop ëŒ€ì‹  Trainerë¥¼ ì¨ì•¼ í•˜ëŠ” ì´ìœ . Custom Callbackì„ ì´ìš©í•œ ì‹¤ì‹œê°„ ìƒì„± í‰ê°€ì™€ íš¨ìœ¨ì ì¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì „ëµ.]]></summary></entry><entry><title type="html">[Transformers] LLM ê²½ëŸ‰í™”ì™€ ê°€ì†: Quantizationë¶€í„° Flash Attentionê¹Œì§€</title><link href="https://ssolllll.github.io/blog/2025/bitsandbytes/" rel="alternate" type="text/html" title="[Transformers] LLM ê²½ëŸ‰í™”ì™€ ê°€ì†: Quantizationë¶€í„° Flash Attentionê¹Œì§€"/><published>2025-12-12T10:00:00+00:00</published><updated>2025-12-12T10:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/bitsandbytes</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/bitsandbytes/"><![CDATA[<p>ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë‹¤ë£° ë•Œ ê°€ì¥ í° ì¥ë²½ì€ â€˜ë¹„ìš©â€™ì´ë‹¤. ìˆ˜ì²œë§Œ ì›ì§œë¦¬ A100 GPUë¥¼ ë§ˆìŒê» ì“¸ ìˆ˜ ìˆë‹¤ë©´ ì¢‹ê² ì§€ë§Œ, í˜„ì‹¤ì€ ì œí•œëœ VRAM(24GB, 48GB) ì•ˆì—ì„œ ìµœëŒ€í•œì˜ ì„±ëŠ¥ì„ ë½‘ì•„ë‚´ì•¼ í•œë‹¤.</p> <p>ë‹¤í–‰íˆ Hugging Face ìƒíƒœê³„ëŠ” <strong>ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ”(Quantization)</strong> ê¸°ìˆ ê³¼ <strong>ì—°ì‚° ì†ë„ë¥¼ ë†’ì´ëŠ”(Acceleration)</strong> ê¸°ìˆ ì„ ë§¤ìš° ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í†µí•©í•´ ë‘ì—ˆë‹¤.</p> <p>ì´ë²ˆ ì‹œë¦¬ì¦ˆì˜ ë§ˆì§€ë§‰ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì—ì„œ ë°˜ë“œì‹œ ì ìš©í•´ì•¼ í•  3ê°€ì§€ ìµœì í™” ê¸°ë²•ì„ ë‹¤ë£¬ë‹¤.</p> <hr/> <h2 id="1-quantization-4-bitì˜-ë§ˆë²•-feat-bitsandbytes">1. Quantization: 4-bitì˜ ë§ˆë²• (feat. BitsAndBytes)</h2> <p>ì–‘ìí™”(Quantization)ëŠ” 32ë¹„íŠ¸(float32)ë‚˜ 16ë¹„íŠ¸(float16)ë¡œ í‘œí˜„ëœ ê°€ì¤‘ì¹˜ë¥¼ 8ë¹„íŠ¸(int8) ë˜ëŠ” 4ë¹„íŠ¸(nf4)ë¡œ ì••ì¶•í•˜ì—¬ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì´ë‹¤. ë†€ë¼ìš´ ì ì€ 4ë¹„íŠ¸ë¡œ ì¤„ì—¬ë„ ëª¨ë¸ì˜ ì„±ëŠ¥ ì €í•˜ê°€ ë¯¸ë¯¸í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="-bad-practice-ë¬´ì¡°ê±´-ì›ë³¸-ë¡œë“œ">ğŸ”´ Bad Practice: ë¬´ì¡°ê±´ ì›ë³¸ ë¡œë“œ</h3> <p>70B ëª¨ë¸ì„ fp16ìœ¼ë¡œ ë¡œë“œí•˜ë©´ ì•½ 140GBì˜ VRAMì´ í•„ìš”í•˜ë‹¤. ì´ëŠ” A100(80GB) 2ì¥ì„ ì¨ì•¼ ê²¨ìš° ì˜¬ë¼ê°€ëŠ” í¬ê¸°ë‹¤.</p> <h3 id="-best-practice-bitsandbytesconfig-4-bit-loading">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">BitsAndBytesConfig</code> (4-bit Loading)</h3> <p><code class="language-plaintext highlighter-rouge">bitsandbytes</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ëª¨ë¸ì„ 4ë¹„íŠ¸ë¡œ ë¡œë“œí•˜ë©´ ìš©ëŸ‰ì´ ì•½ 1/4ë¡œ ì¤„ì–´ë“ ë‹¤. ì´ë¥¼ í†µí•´ <strong>Llama-2-70B ëª¨ë¸ì„ 48GB GPU(A6000, L40) í•œ ì¥</strong>ì— ì˜¬ë¦´ ìˆ˜ ìˆë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>

<span class="c1"># 4bit ì–‘ìí™” ì„¤ì • (QLoRA í•™ìŠµ ì‹œ í•„ìˆ˜)
</span><span class="n">bnb_config</span> <span class="o">=</span> <span class="nc">BitsAndBytesConfig</span><span class="p">(</span>
    <span class="n">load_in_4bit</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="sh">"</span><span class="s">nf4</span><span class="sh">"</span><span class="p">,</span>       <span class="c1"># ì •ê·œë¶„í¬ì— ìµœì í™”ëœ Normal Float 4
</span>    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="c1"># ì—°ì‚°ì€ bf16ìœ¼ë¡œ ìˆ˜í–‰ (ì†ë„/ì„±ëŠ¥ ë³´ì¡´)
</span>    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># ì–‘ìí™” ìƒìˆ˜ë¥¼ í•œ ë²ˆ ë” ì–‘ìí™” (ë©”ëª¨ë¦¬ ì¶”ê°€ ì ˆì•½)
</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">meta-llama/Llama-2-70b-hf</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="o">=</span><span class="n">bnb_config</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span>
<span class="p">)</span>
</code></pre></div></div> <p>ì´ ì„¤ì •ì€ íŒŒì¸íŠœë‹ ê¸°ë²•ì¸ <strong>QLoRA(Quantized LoRA)</strong>ì˜ ê¸°ë°˜ì´ ë˜ë©°, ì†Œë¹„ììš© GPU(RTX 3090/4090)ì—ì„œë„ LLM í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“  ì¼ë“±ê³µì‹ ì´ë‹¤.</p> <hr/> <h2 id="2-flash-attention-2-ë©”ëª¨ë¦¬-ëŒ€ì—­í­-ë³‘ëª©-í•´ì†Œ">2. Flash Attention 2: ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ë³‘ëª© í•´ì†Œ</h2> <p>Transformer êµ¬ì¡°ì˜ í•µì‹¬ì¸ Attention ë©”ì»¤ë‹ˆì¦˜ì€ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´($N$)ì˜ ì œê³±($N^2$)ì— ë¹„ë¡€í•˜ì—¬ ì—°ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•œë‹¤. ë¬¸ì¥ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ê¸‰ê²©íˆ ëŠë ¤ì§€ëŠ” ì´ìœ ë‹¤.</p> <p><strong>Flash Attention</strong>ì€ GPU ë©”ëª¨ë¦¬(HBM) ì ‘ê·¼ íšŸìˆ˜ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬(IO-Aware), ê¸´ ë¬¸ë§¥ ì²˜ë¦¬ ì†ë„ë¥¼ 2ë°° ì´ìƒ ë¹ ë¥´ê²Œ ë§Œë“ ë‹¤.</p> <h3 id="ì ìš©-ë°©ë²•">ì ìš© ë°©ë²•</h3> <p>ë³µì¡í•œ êµ¬í˜„ ì—†ì´ <code class="language-plaintext highlighter-rouge">use_flash_attention_2=True</code> ì˜µì…˜ë§Œ ì¼œë©´ ëœë‹¤. (ë‹¨, Ampere ì•„í‚¤í…ì²˜ ì´ìƒì˜ GPU í•„ìš”: A100, A10, RTX 30/40 ì‹œë¦¬ì¦ˆ)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">meta-llama/Llama-2-7b-chat-hf</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">,</span> 
    <span class="n">attn_implementation</span><span class="o">=</span><span class="sh">"</span><span class="s">flash_attention_2</span><span class="sh">"</span> <span class="c1"># í•µì‹¬ ì˜µì…˜
</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p><strong>Benchmark:</strong> ì…ë ¥ í† í°ì´ 4096 ì´ìƒì¼ ë•Œ, ì¼ë°˜ Attention ëŒ€ë¹„ <strong>2~3ë°°ì˜ ì†ë„ í–¥ìƒ</strong>ê³¼ ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±)ì²˜ëŸ¼ ê¸´ ë¬¸ì„œë¥¼ ë‹¤ë£¨ëŠ” ì„œë¹„ìŠ¤ì—ì„œëŠ” í•„ìˆ˜ ì˜µì…˜ì´ë‹¤.</p> </blockquote> <hr/> <h2 id="3-kv-cache-í–ˆë˜-ê³„ì‚°-ë˜-í•˜ì§€-ì•Šê¸°">3. KV Cache: í–ˆë˜ ê³„ì‚° ë˜ í•˜ì§€ ì•Šê¸°</h2> <p>LLMì€ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•  ë•Œ, ì´ì „ì˜ ëª¨ë“  í† í° ì •ë³´ë¥¼ ë‹¤ì‹œ ì°¸ì¡°í•œë‹¤. ë§¤ë²ˆ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ì—„ì²­ë‚œ ë‚­ë¹„ë‹¤. <strong>Key-Value (KV) Cache</strong>ëŠ” ì´ì „ í† í°ë“¤ì˜ ì—°ì‚° ê²°ê³¼(Key, Value)ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•´ë‘ê³  ì¬ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ ì´ë‹¤.</p> <h3 id="-best-practice-use_cachetrue">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">use_cache=True</code></h3> <p>ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì—ì„œ ê¸°ë³¸ê°’ì€ <code class="language-plaintext highlighter-rouge">True</code>ì´ì§€ë§Œ, í•™ìŠµ(Training) ì‹œì—ëŠ” ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ <code class="language-plaintext highlighter-rouge">False</code>ë¡œ ë„ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ë”°ë¼ì„œ <strong>ì¶”ë¡ (Inference) ë‹¨ê³„ì—ì„œëŠ” ë°˜ë“œì‹œ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸</strong>í•´ì•¼ í•œë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 1. ëª¨ë¸ ì„¤ì •ì—ì„œ í™•ì¸
</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># 2. generation í˜¸ì¶œ ì‹œ ëª…ì‹œ
</span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="o">=</span><span class="bp">True</span> 
<span class="p">)</span>
</code></pre></div></div> <p>KV Cacheë¥¼ ë„ë©´ ë¬¸ì¥ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ìƒì„± ì†ë„ê°€ ì„ í˜•ì ìœ¼ë¡œ ëŠë ¤ì§€ì§€ë§Œ, ì¼œë©´ ë¬¸ì¥ ê¸¸ì´ì— ìƒê´€ì—†ì´ ì¼ì •í•œ ì†ë„(O(1) per token)ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.</p> <hr/> <h2 id="series-conclusion-llm-ì—”ì§€ë‹ˆì–´ë§ì˜-ì—¬ì •">Series Conclusion: LLM ì—”ì§€ë‹ˆì–´ë§ì˜ ì—¬ì •</h2> <p>ì´ 5í¸ì— ê±¸ì³ <code class="language-plaintext highlighter-rouge">transformers</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ LLM ì—”ì§€ë‹ˆì–´ë§ í•µì‹¬ ê¸°ìˆ ì„ ì‚´í´ë³´ì•˜ë‹¤.</p> <ol> <li><strong>Tokenizer:</strong> Rust ê¸°ë°˜ ê°€ì†ê³¼ Dynamic Paddingìœ¼ë¡œ ì…ë ¥ íŒŒì´í”„ë¼ì¸ ìµœì í™”.</li> <li><strong>Model Loading:</strong> <code class="language-plaintext highlighter-rouge">device_map</code>ê³¼ <code class="language-plaintext highlighter-rouge">fp16</code>ìœ¼ë¡œ OOM ì—†ëŠ” ë¡œë”©.</li> <li><strong>Inference:</strong> <code class="language-plaintext highlighter-rouge">GenerationConfig</code>ì™€ <code class="language-plaintext highlighter-rouge">Streamer</code>ë¡œ ìƒìš© ìˆ˜ì¤€ì˜ ì„œë¹„ìŠ¤ êµ¬í˜„.</li> <li><strong>Training:</strong> <code class="language-plaintext highlighter-rouge">Trainer</code>ì™€ <code class="language-plaintext highlighter-rouge">Callback</code>ìœ¼ë¡œ ì•ˆì •ì ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•.</li> <li><strong>Optimization:</strong> <code class="language-plaintext highlighter-rouge">Quantization</code>ê³¼ <code class="language-plaintext highlighter-rouge">Flash Attention</code>ìœ¼ë¡œ ê·¹í•œì˜ íš¨ìœ¨ì„± ë‹¬ì„±.</li> </ol> <p>ì´ ì‹œë¦¬ì¦ˆê°€ ë‹¨ìˆœí•œ ì½”ë“œ ë³µì‚¬-ë¶™ì—¬ë„£ê¸°ë¥¼ ë„˜ì–´, <strong>â€œì™œ ì´ë ‡ê²Œ ì„¤ì •í•´ì•¼ í•˜ëŠ”ê°€?â€</strong>ì— ëŒ€í•œ ì—”ì§€ë‹ˆì–´ë§ì  í†µì°°ì„ ì œê³µí–ˆê¸°ë¥¼ ë°”ë€ë‹¤. ì´ì œ ì—¬ëŸ¬ë¶„ì˜ ë°ì´í„°ë¥¼ ëª¨ë¸ì— íƒœì›Œë³¼ ì°¨ë¡€ë‹¤. Happy Engineering!</p>]]></content><author><name></name></author><category term="engineering"/><category term="python"/><category term="transformers"/><category term="quantization"/><category term="optimization"/><category term="cuda"/><summary type="html"><![CDATA[BitsAndBytesë¥¼ í™œìš©í•œ 4bit ì–‘ìí™”(QLoRA) ì›ë¦¬ì™€ Flash Attention 2 ì ìš©ë²•. KV Cacheì˜ ì¤‘ìš”ì„±ê¹Œì§€, ëª¨ë¸ ì„±ëŠ¥ì„ ê·¹í•œìœ¼ë¡œ ëŒì–´ì˜¬ë¦¬ëŠ” ìµœì í™” ê¸°ë²• ì´ì •ë¦¬.]]></summary></entry><entry><title type="html">[Transformers] LLM ì„±ëŠ¥ì˜ ì‹œì‘ì , Tokenizer ìµœì í™” ë° í™œìš© ì „ëµ</title><link href="https://ssolllll.github.io/blog/2025/transformers-optimization/" rel="alternate" type="text/html" title="[Transformers] LLM ì„±ëŠ¥ì˜ ì‹œì‘ì , Tokenizer ìµœì í™” ë° í™œìš© ì „ëµ"/><published>2025-12-07T18:00:00+00:00</published><updated>2025-12-07T18:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/transformers-optimization</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/transformers-optimization/"><![CDATA[<p>LLM ì—”ì§€ë‹ˆì–´ë§ì—ì„œ ëª¨ë¸(Model) ì•„í‚¤í…ì²˜ë‚˜ ì–‘ìí™”(Quantization)ì—ëŠ” ë§ì€ ê´€ì‹¬ì„ ê°–ì§€ë§Œ, ì •ì‘ ë°ì´í„°ê°€ ëª¨ë¸ë¡œ ë“¤ì–´ê°€ëŠ” ì²« ê´€ë¬¸ì¸ <strong>Tokenizer</strong>ì˜ íš¨ìœ¨ì„±ì€ ê°„ê³¼í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.</p> <p>í•˜ì§€ë§Œ ìˆ˜ì‹­ ê¸°ê°€ë°”ì´íŠ¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” Pre-training/Fine-tuning ë‹¨ê³„ë‚˜, ì‹¤ì‹œê°„ìœ¼ë¡œ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” Serving ë‹¨ê³„ì—ì„œ ë¹„íš¨ìœ¨ì ì¸ Tokenizer ì‚¬ìš©ì€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ <strong>ì‹¬ê°í•œ ë³‘ëª©(Bottleneck)</strong>ì´ ë  ìˆ˜ ìˆë‹¤.</p> <p>ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” <code class="language-plaintext highlighter-rouge">transformers</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Tokenizerë¥¼ ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì—ì„œ 100% í™œìš©í•˜ëŠ” ì„¸ ê°€ì§€ í•µì‹¬ ì „ëµì„ ë‹¤ë£¬ë‹¤.</p> <hr/> <h2 id="1-fast-tokenizer-rustì˜-ì†ë„ë¥¼-ë¹Œë ¤ë¼">1. Fast Tokenizer: Rustì˜ ì†ë„ë¥¼ ë¹Œë ¤ë¼</h2> <p>Hugging Faceì˜ <code class="language-plaintext highlighter-rouge">transformers</code>ëŠ” ë‘ ê°€ì§€ íƒ€ì…ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ì œê³µí•œë‹¤.</p> <ol> <li><strong>Python Tokenizer:</strong> ìˆœìˆ˜ íŒŒì´ì¬ êµ¬í˜„ì²´. ëŠë¦¬ë‹¤.</li> <li><strong>Fast Tokenizer:</strong> Rustë¡œ êµ¬í˜„ëœ <code class="language-plaintext highlighter-rouge">tokenizers</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ ë˜í¼(Wrapper). ë§¤ìš° ë¹ ë¥´ë‹¤.</li> </ol> <p>ëŒ€ë¶€ë¶„ <code class="language-plaintext highlighter-rouge">AutoTokenizer.from_pretrained()</code>ë¥¼ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ Fast ë²„ì „ì„ ê°€ì ¸ì˜¤ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ í™•ì¸í•˜ê³  ì‚¬ìš©í•˜ëŠ” ìŠµê´€ì´ ì¤‘ìš”í•˜ë‹¤.</p> <h3 id="-ì„±ëŠ¥-ì°¨ì´-ë²¤ì¹˜ë§ˆí¬">âš¡ ì„±ëŠ¥ ì°¨ì´ ë²¤ì¹˜ë§ˆí¬</h3> <p>ìˆ˜ë°±ë§Œ ê±´ì˜ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•  ë•Œ, ì´ ì†ë„ ì°¨ì´ëŠ” ë°ì´í„° ë¡œë”© ì‹œê°„(Data Loading Time)ì„ ëª‡ ì‹œê°„ì—ì„œ ëª‡ ë¶„ìœ¼ë¡œ ì¤„ì—¬ì¤€ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="n">model_id</span> <span class="o">=</span> <span class="sh">"</span><span class="s">gpt2</span><span class="sh">"</span>
<span class="n">text</span> <span class="o">=</span> <span class="sh">"</span><span class="s">The quick brown fox jumps over the lazy dog.</span><span class="sh">"</span> <span class="o">*</span> <span class="mi">1000</span>

<span class="c1"># 1. Slow Tokenizer (Python)
</span><span class="n">slow_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="nf">slow_tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Slow: </span><span class="si">{</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> sec</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. Fast Tokenizer (Rust)
</span><span class="n">fast_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="nf">fast_tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Fast: </span><span class="si">{</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> sec</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># ê²°ê³¼ ì˜ˆì‹œ:
# Slow: 1.2031 sec
# Fast: 0.1054 sec (ì•½ 10ë°° ì´ìƒ ë¹ ë¦„)
</span></code></pre></div></div> <blockquote> <p><strong>Tip:</strong> <code class="language-plaintext highlighter-rouge">FastTokenizer</code>ëŠ” ë³‘ë ¬ ì²˜ë¦¬(Parallelism) ê¸°ëŠ¥ë„ ë‚´ì¥í•˜ê³  ìˆì–´, <code class="language-plaintext highlighter-rouge">batched=True</code> ì˜µì…˜ê³¼ í•¨ê»˜ ì‚¬ìš© ì‹œ CPU ì½”ì–´ë¥¼ ìµœëŒ€í•œ í™œìš©í•œë‹¤.</p> </blockquote> <hr/> <h2 id="2-dynamic-padding-ë¶ˆí•„ìš”í•œ-ì—°ì‚°ëŸ‰-ì¤„ì´ê¸°">2. Dynamic Padding: ë¶ˆí•„ìš”í•œ ì—°ì‚°ëŸ‰ ì¤„ì´ê¸°</h2> <p>LLMì€ ë°°ì²˜(Batch) ì²˜ë¦¬ë¥¼ ìœ„í•´ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ë¥¼ í†µì¼í•´ì•¼ í•œë‹¤. ì´ë•Œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ì±„ìš°ëŠ” ê²ƒì´ <strong>Padding</strong>ì´ë‹¤.</p> <h3 id="-bad-practice-ê³ ì •-ê¸¸ì´-padding">ğŸ”´ Bad Practice: ê³ ì • ê¸¸ì´ Padding</h3> <p>ëª¨ë“  ë°ì´í„°ë¥¼ ëª¨ë¸ì˜ <code class="language-plaintext highlighter-rouge">max_length</code>(ì˜ˆ: 2048)ì— ë§ì¶° íŒ¨ë”©í•˜ë©´, â€œHelloâ€ ê°™ì€ ì§§ì€ ë¬¸ì¥ë„ 2043ê°œì˜ íŒ¨ë”© í† í°(<code class="language-plaintext highlighter-rouge">pad_token</code>)ì„ ê³„ì‚°í•´ì•¼ í•œë‹¤. ì´ëŠ” GPU ë©”ëª¨ë¦¬ì™€ ì—°ì‚°ë ¥ì˜ ë‚­ë¹„ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ë¹„íš¨ìœ¨ì ì¸ ë°©ì‹: ë¬´ì¡°ê±´ max_lengthê¹Œì§€ ëŠ˜ë¦¼
</span><span class="n">tokenized</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span>
    <span class="p">[</span><span class="sh">"</span><span class="s">Hello</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Hi</span><span class="sh">"</span><span class="p">],</span> 
    <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> 
    <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
<span class="c1"># ê²°ê³¼: [Hello, PAD, PAD, ..., PAD] -&gt; ë¶ˆí•„ìš”í•œ ì—°ì‚° ë°œìƒ
</span></code></pre></div></div> <h3 id="-best-practice-dynamic-padding-datacollator">ğŸŸ¢ Best Practice: Dynamic Padding (DataCollator)</h3> <p>ë°°ì¹˜(Batch) ë‚´ì—ì„œ <strong>ê°€ì¥ ê¸´ ë¬¸ì¥ì˜ ê¸¸ì´ì— ë§ì¶°ì„œ</strong> íŒ¨ë”©í•˜ëŠ” ë°©ì‹ì´ë‹¤. ë°ì´í„°ì…‹ ì „ì²´ê°€ ì•„ë‹Œ, ë¯¸ë‹ˆ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê¸¸ì´ë¥¼ ë§ì¶”ë¯€ë¡œ ì—°ì‚°ëŸ‰ì´ íšê¸°ì ìœ¼ë¡œ ì¤„ì–´ë“ ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorWithPadding</span>

<span class="c1"># ë°ì´í„°ì…‹ ë‹¨ê³„ì—ì„œëŠ” íŒ¨ë”©í•˜ì§€ ì•ŠìŒ (truncationë§Œ ì ìš©)
</span><span class="k">def</span> <span class="nf">preprocess_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># DataLoaderê°€ ë°°ì¹˜ë¥¼ ë§Œë“¤ ë•Œ íŒ¨ë”© ìˆ˜í–‰
</span><span class="n">data_collator</span> <span class="o">=</span> <span class="nc">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="c1"># Trainerë‚˜ DataLoaderì— collator ì „ë‹¬
# trainer = Trainer(..., data_collator=data_collator)
</span></code></pre></div></div> <p>ì´ ë°©ì‹ì„ ì ìš©í•˜ë©´ í•™ìŠµ ì†ë„ê°€ ë°ì´í„° ê¸¸ì´ì— ë”°ë¼ <strong>20~30% ì´ìƒ í–¥ìƒ</strong>ë  ìˆ˜ ìˆë‹¤.</p> <hr/> <h2 id="3-chat-template-í”„ë¡¬í”„íŠ¸-ì—”ì§€ë‹ˆì–´ë§ì˜-í‘œì¤€í™”">3. Chat Template: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ í‘œì¤€í™”</h2> <p>LLMë§ˆë‹¤ ìš”êµ¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í¬ë§·ì´ ë‹¤ë¥´ë‹¤. (Llama-2ì˜ <code class="language-plaintext highlighter-rouge">[INST]</code>, ChatMLì˜ <code class="language-plaintext highlighter-rouge">&lt;|im_start|&gt;</code>, Alphaì˜ <code class="language-plaintext highlighter-rouge">Human:</code> ë“±) ì´ë¥¼ í•˜ë“œì½”ë”©ìœ¼ë¡œ ë¬¸ìì—´ì„ í•©ì¹˜ëŠ” ë°©ì‹ì€ ëª¨ë¸ êµì²´ ì‹œ ì½”ë“œë¥¼ ì „ë©´ ìˆ˜ì •í•´ì•¼ í•˜ëŠ” ë¦¬ìŠ¤í¬ê°€ ìˆë‹¤.</p> <h3 id="apply_chat_template-í™œìš©"><code class="language-plaintext highlighter-rouge">apply_chat_template</code> í™œìš©</h3> <p><code class="language-plaintext highlighter-rouge">transformers</code> 4.34.0ë¶€í„° ë„ì…ëœ ì´ ê¸°ëŠ¥ì€ ëª¨ë¸ì˜ <code class="language-plaintext highlighter-rouge">tokenizer_config.json</code>ì— ì •ì˜ëœ í…œí”Œë¦¿ì„ ìë™ìœ¼ë¡œ ì ìš©í•´ì¤€ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">RAG ì‹œìŠ¤í…œì˜ ì¥ì ì€?</span><span class="sh">"</span><span class="p">},</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.</span><span class="sh">"</span><span class="p">},</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">ë‹¨ì ì€?</span><span class="sh">"</span><span class="p">}</span>
<span class="p">]</span>

<span class="c1"># ëª¨ë¸ì— ë§ëŠ” í¬ë§·ìœ¼ë¡œ ìë™ ë³€í™˜
</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">apply_chat_template</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">,</span> 
    <span class="n">tokenize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
    <span class="n">add_generation_prompt</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="c1"># Llama-2ì¸ ê²½ìš°: &lt;s&gt;[INST] RAG ì‹œìŠ¤í…œì˜ ì¥ì ì€? [/INST] ìµœì‹  ì •ë³´ë¥¼ ... &lt;/s&gt;&lt;s&gt;[INST] ë‹¨ì ì€? [/INST]
# Mistralì¸ ê²½ìš°: ... (í•´ë‹¹ ëª¨ë¸ í¬ë§· ìë™ ì ìš©)
</span></code></pre></div></div> <p>ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ <strong>ëª¨ë¸ ì˜ì¡´ì„±(Model Dependency)ì„ ì½”ë“œì—ì„œ ë¶„ë¦¬</strong>í•  ìˆ˜ ìˆì–´, ì—¬ëŸ¬ ëª¨ë¸ì„ ì‹¤í—˜í•˜ê±°ë‚˜ A/B í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ë•Œ ìœ ì§€ë³´ìˆ˜ì„±ì´ ê·¹ëŒ€í™”ëœë‹¤.</p> <hr/> <h2 id="ê²°ë¡ ">ê²°ë¡ </h2> <p>TokenizerëŠ” ë‹¨ìˆœíˆ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬ ë„êµ¬ê°€ ì•„ë‹ˆë‹¤.</p> <ul> <li><strong>Rust ê¸°ë°˜ Fast Tokenizer</strong>ë¡œ CPU ë³‘ëª©ì„ í•´ì†Œí•˜ê³ ,</li> <li><strong>Dynamic Padding</strong>ìœ¼ë¡œ GPU ì—°ì‚° íš¨ìœ¨ì„ ë†’ì´ë©°,</li> <li><strong>Chat Template</strong>ìœ¼ë¡œ ì½”ë“œì˜ ìœ ì—°ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒ.</li> </ul> <p>ì´ê²ƒì´ LLM ì—”ì§€ë‹ˆì–´ê°€ ê°–ì¶°ì•¼ í•  â€œì…ë ¥ íŒŒì´í”„ë¼ì¸ ìµœì í™”â€ì˜ ê¸°ë³¸ê¸°ë‹¤. ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì´ë ‡ê²Œ ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ê±°ëŒ€ ëª¨ë¸ì— íš¨ìœ¨ì ìœ¼ë¡œ ì ì¬í•˜ëŠ” <strong>Model Loading ì „ëµ</strong>ì— ëŒ€í•´ ë‹¤ë£¨ê² ë‹¤.</p>]]></content><author><name></name></author><category term="engineering"/><category term="python"/><category term="transformers"/><category term="llm"/><category term="optimization"/><category term="nlp"/><summary type="html"><![CDATA[Hugging Face Tokenizerì˜ Rust ê¸°ë°˜ ê°€ì†, Dynamic Paddingì„ í†µí•œ ì—°ì‚°ëŸ‰ ì ˆê°, ê·¸ë¦¬ê³  Chat Templateì„ í™œìš©í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í‘œì¤€í™” ê°€ì´ë“œ.]]></summary></entry><entry><title type="html">[Transformers] LLM ì¶”ë¡  ì œì–´: GenerationConfigì™€ ì‹¤ì‹œê°„ Streaming êµ¬í˜„</title><link href="https://ssolllll.github.io/blog/2025/generation_config_streaming/" rel="alternate" type="text/html" title="[Transformers] LLM ì¶”ë¡  ì œì–´: GenerationConfigì™€ ì‹¤ì‹œê°„ Streaming êµ¬í˜„"/><published>2025-12-07T10:00:00+00:00</published><updated>2025-12-07T10:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/generation_config_streaming</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/generation_config_streaming/"><![CDATA[<p>LLMì„ ì„œë¹„ìŠ¤ì— ë„ì…í•  ë•Œ ì‚¬ìš©ìë“¤ì´ ê°€ì¥ ë¨¼ì € ì²´ê°í•˜ëŠ” ì„±ëŠ¥ ì§€í‘œëŠ” ë¬´ì—‡ì¼ê¹Œ? ì „ì²´ ë‹µë³€ì´ ì™„ì„±ë˜ëŠ” ì‹œê°„(Total Latency)ë³´ë‹¤, <strong>ì²« ë²ˆì§¸ ê¸€ìê°€ í™”ë©´ì— ì°íˆëŠ” ì‹œê°„(TTFT, Time To First Token)</strong>ì´ë‹¤.</p> <p><code class="language-plaintext highlighter-rouge">model.generate()</code> í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ìƒì„±ì´ ëë‚  ë•Œê¹Œì§€ ë¸”ë¡œí‚¹(Blocking)ëœë‹¤. ì±—ë´‡ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©ìì—ê²Œ 10ì´ˆ ë™ì•ˆ ë¡œë”© ë°”ë§Œ ë³´ì—¬ì£¼ëŠ” ê²ƒì€ ìµœì•…ì˜ ê²½í—˜ì´ë‹¤.</p> <p>ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” <code class="language-plaintext highlighter-rouge">transformers</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ <strong>ChatGPTì²˜ëŸ¼ ê¸€ìê°€ íƒ€ë‹¥íƒ€ë‹¥ ì°íˆëŠ” ìŠ¤íŠ¸ë¦¬ë°</strong>ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ê³¼, ë³µì¡í•œ ìƒì„± í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì½”ë“œê°€ ì•„ë‹Œ ì„¤ì • íŒŒì¼ë¡œ ê´€ë¦¬í•˜ëŠ” <strong>GenerationConfig</strong> í™œìš©ë²•ì„ ë‹¤ë£¬ë‹¤.</p> <hr/> <h2 id="1-generationconfig-íŒŒë¼ë¯¸í„°-í•˜ë“œì½”ë”©-ë©ˆì¶°">1. GenerationConfig: íŒŒë¼ë¯¸í„° í•˜ë“œì½”ë”© ë©ˆì¶°!</h2> <p><code class="language-plaintext highlighter-rouge">temperature</code>, <code class="language-plaintext highlighter-rouge">top_p</code>, <code class="language-plaintext highlighter-rouge">repetition_penalty</code> ë“± LLMì˜ ë‹µë³€ í’ˆì§ˆì„ ê²°ì •í•˜ëŠ” ìˆ˜ë§ì€ íŒŒë¼ë¯¸í„°ë“¤ì´ ìˆë‹¤. ì´ë¥¼ í•¨ìˆ˜ ì¸ìì— í•˜ë“œì½”ë”©í•˜ëŠ” ê²ƒì€ ìœ ì§€ë³´ìˆ˜ ì¸¡ë©´ì—ì„œ ì¢‹ì§€ ì•Šë‹¤.</p> <h3 id="-bad-practice-í•˜ë“œì½”ë”©">ğŸ”´ Bad Practice: í•˜ë“œì½”ë”©</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ì½”ë“œë¥¼ ìˆ˜ì •í•´ì•¼ë§Œ ë‹µë³€ ìŠ¤íƒ€ì¼ì„ ë°”ê¿€ ìˆ˜ ìˆìŒ
</span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> 
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> 
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <h3 id="-best-practice-generationconfig-ê°ì²´-ì‚¬ìš©">ğŸŸ¢ Best Practice: GenerationConfig ê°ì²´ ì‚¬ìš©</h3> <p><code class="language-plaintext highlighter-rouge">GenerationConfig</code>ë¥¼ ì‚¬ìš©í•˜ë©´ íŒŒë¼ë¯¸í„°ë¥¼ ê°ì²´ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, JSONìœ¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ë¶ˆëŸ¬ì˜¤ê¸°ê°€ ì‰¬ì›Œ <strong>MLOps(ì‹¤í—˜ ê´€ë¦¬)</strong> ê´€ì ì—ì„œ ìœ ë¦¬í•˜ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">GenerationConfig</span>

<span class="c1"># 1. ì„¤ì • ìƒì„± ë° ì €ì¥
</span><span class="n">config</span> <span class="o">=</span> <span class="nc">GenerationConfig</span><span class="p">(</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.1</span>
<span class="p">)</span>
<span class="n">config</span><span class="p">.</span><span class="nf">save_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">./my_chat_config</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 2. ë¡œë“œ ë° ì‚¬ìš© (ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  ì„¤ì • íŒŒì¼ë§Œ ë°”ê¿”ì„œ ë°°í¬ ê°€ëŠ¥)
</span><span class="n">loaded_config</span> <span class="o">=</span> <span class="n">GenerationConfig</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">./my_chat_config</span><span class="sh">"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">generation_config</span><span class="o">=</span><span class="n">loaded_config</span><span class="p">)</span>
</code></pre></div></div> <blockquote> <p><strong>Tip:</strong> ëª¨ë¸ë§ˆë‹¤ â€œì°½ì˜ì ì¸ ëª¨ë“œâ€, â€œì •í™•í•œ ëª¨ë“œâ€ ë“± ì—¬ëŸ¬ í”„ë¦¬ì…‹ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ê³  <code class="language-plaintext highlighter-rouge">config</code>ë§Œ êµì²´í•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.</p> </blockquote> <hr/> <h2 id="2-streamer-ì‹¤ì‹œê°„-í† í°-ì¶œë ¥-feat-thread">2. Streamer: ì‹¤ì‹œê°„ í† í° ì¶œë ¥ (Feat. Thread)</h2> <p>ì‚¬ìš©ì ê²½í—˜(UX)ì„ í˜ì‹ ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ìŠ¤íŠ¸ë¦¬ë°ì€ <code class="language-plaintext highlighter-rouge">TextIteratorStreamer</code>ë¥¼ í†µí•´ êµ¬í˜„í•œë‹¤. í•µì‹¬ì€ <code class="language-plaintext highlighter-rouge">model.generate()</code>ê°€ ë©”ì¸ ìŠ¤ë ˆë“œë¥¼ ì ìœ í•˜ì§€ ì•Šë„ë¡ <strong>ë³„ë„ ìŠ¤ë ˆë“œ(Thread)</strong>ì—ì„œ ì‹¤í–‰í•´ì•¼ í•œë‹¤ëŠ” ì ì´ë‹¤.</p> <h3 id="êµ¬í˜„-íŒ¨í„´-standard-pattern">êµ¬í˜„ íŒ¨í„´ (Standard Pattern)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">threading</span> <span class="kn">import</span> <span class="n">Thread</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">TextIteratorStreamer</span>

<span class="c1"># 1. Streamer ì¤€ë¹„
# skip_prompt=True: ì…ë ¥í–ˆë˜ ì§ˆë¬¸ì€ ë‹¤ì‹œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
</span><span class="n">streamer</span> <span class="o">=</span> <span class="nc">TextIteratorStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">skip_prompt</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 2. Generate í•¨ìˆ˜ì— ì „ë‹¬í•  ì¸ì ì¤€ë¹„
</span><span class="n">generate_kwargs</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span><span class="p">,</span>
    <span class="n">generation_config</span><span class="o">=</span><span class="n">loaded_config</span>
<span class="p">)</span>

<span class="c1"># 3. ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìƒì„± ì‹œì‘ (Non-blocking)
# threadë¥¼ ì“°ì§€ ì•Šìœ¼ë©´ generateê°€ ëë‚  ë•Œê¹Œì§€ ì•„ë˜ forë¬¸ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
</span><span class="n">thread</span> <span class="o">=</span> <span class="nc">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="p">)</span>
<span class="n">thread</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>

<span class="c1"># 4. ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œëŠ” Streamerì—ì„œ ë‚˜ì˜¤ëŠ” í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì†Œë¹„
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Assistant: </span><span class="sh">"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="sh">""</span><span class="p">)</span>
<span class="k">for</span> <span class="n">new_text</span> <span class="ow">in</span> <span class="n">streamer</span><span class="p">:</span>
    <span class="c1"># ì—¬ê¸°ì„œ WebSocketì´ë‚˜ Server-Sent Events(SSE)ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
</span>    <span class="nf">print</span><span class="p">(</span><span class="n">new_text</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="sh">""</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
</span><span class="n">thread</span><span class="p">.</span><span class="nf">join</span><span class="p">()</span>
</code></pre></div></div> <p>ì´ ì½”ë“œëŠ” <code class="language-plaintext highlighter-rouge">FastAPI</code>ë‚˜ <code class="language-plaintext highlighter-rouge">Flask</code> ê°™ì€ ë°±ì—”ë“œ í”„ë ˆì„ì›Œí¬ì™€ ê²°í•©í•˜ì—¬ <strong>SSE(Server-Sent Events)</strong> ì—”ë“œí¬ì¸íŠ¸ë¥¼ êµ¬ì¶•í•  ë•Œ ê·¸ëŒ€ë¡œ ì‚¬ìš©ë˜ëŠ” í•µì‹¬ ë¡œì§ì´ë‹¤.</p> <hr/> <h2 id="3-stoppingcriteria-ìƒì„±ì„-ê°•ì œë¡œ-ë©ˆì¶”ëŠ”-ì•ˆì „ì¥ì¹˜">3. StoppingCriteria: ìƒì„±ì„ ê°•ì œë¡œ ë©ˆì¶”ëŠ” ì•ˆì „ì¥ì¹˜</h2> <p>ê°€ë” LLMì´ ë¬¸ì¥ì„ ëë§ºì§€ ëª»í•˜ê³  <code class="language-plaintext highlighter-rouge">\n\nUser: \n\nUser:</code> ì²˜ëŸ¼ ë¬´í•œ ë£¨í”„ì— ë¹ ì§€ê±°ë‚˜, íŠ¹ì • ë‹¨ì–´ê°€ ë‚˜ì˜¤ë©´ ì¦‰ì‹œ ìƒì„±ì„ ë©ˆì¶°ì•¼ í•  ë•Œê°€ ìˆë‹¤. <code class="language-plaintext highlighter-rouge">EOS(End of Sentence)</code> í† í°ë§Œ ë¯¿ê¸°ì—ëŠ” ë¶ˆì•ˆí•˜ë‹¤.</p> <p>ì´ë•Œ <code class="language-plaintext highlighter-rouge">StoppingCriteria</code>ë¥¼ ì‚¬ìš©í•œë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">StoppingCriteria</span><span class="p">,</span> <span class="n">StoppingCriteriaList</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="k">class</span> <span class="nc">StopOnWord</span><span class="p">(</span><span class="n">StoppingCriteria</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stop_word_id</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stop_word_id</span> <span class="o">=</span> <span class="n">stop_word_id</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># ë°©ê¸ˆ ìƒì„±ëœ í† í°ì´ ê¸ˆì§€ì–´(stop_word)ì™€ ê°™ìœ¼ë©´ True ë°˜í™˜ -&gt; ìƒì„± ì¤‘ë‹¨
</span>        <span class="k">return</span> <span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">self</span><span class="p">.</span><span class="n">stop_word_id</span>

<span class="c1"># ì˜ˆ: "###" ì´ë¼ëŠ” í† í°ì´ ë‚˜ì˜¤ë©´ ì¦‰ì‹œ ë©ˆì¶¤
</span><span class="n">stop_criteria</span> <span class="o">=</span> <span class="nc">StoppingCriteriaList</span><span class="p">([</span><span class="nc">StopOnWord</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="sh">"</span><span class="s">###</span><span class="sh">"</span><span class="p">)[</span><span class="mi">0</span><span class="p">])])</span>

<span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">stopping_criteria</span><span class="o">=</span><span class="n">stop_criteria</span>
<span class="p">)</span>
</code></pre></div></div> <p>ì´ ê¸°ëŠ¥ì€ í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ì„ ë°©ì–´í•˜ê±°ë‚˜, ë©€í‹°í„´ ëŒ€í™”ì—ì„œ ëª¨ë¸ì´ ì‚¬ìš©ì ì—­í• ê¹Œì§€ ì—°ê¸°í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ë° í•„ìˆ˜ì ì´ë‹¤.</p> <hr/> <h2 id="ê²°ë¡ ">ê²°ë¡ </h2> <p>LLM ì¶”ë¡  ì œì–´ ê¸°ìˆ ì€ ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë„˜ì–´, <strong>ì‚¬ìš©ìê°€ ê¸°ë‹¤ë¦´ ìˆ˜ ìˆëŠ” ì†ë„</strong>ì™€ <strong>ì˜ë„ëœ ëŒ€ë¡œë§Œ í–‰ë™í•˜ê²Œ í•˜ëŠ” í†µì œê¶Œ</strong>ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ë‹¤.</p> <ul> <li><strong>GenerationConfig:</strong> í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ë²„ì „ ê´€ë¦¬ì™€ ë””ì»¤í”Œë§.</li> <li><strong>Streamer + Thread:</strong> TTFTë¥¼ ì¤„ì´ê³  ì²´ê° ì†ë„ë¥¼ ë†’ì´ëŠ” UXì˜ í•µì‹¬.</li> <li><strong>StoppingCriteria:</strong> ëª¨ë¸ì˜ í­ì£¼ë¥¼ ë§‰ëŠ” ì•ˆì „ì¥ì¹˜.</li> </ul> <p>ì´ì œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³ (<code class="language-plaintext highlighter-rouge">Model Loading</code>), ì…ë ¥ì„ ìµœì í™”í•˜ê³ (<code class="language-plaintext highlighter-rouge">Tokenizer</code>), ì¶œë ¥ì„ ì œì–´(<code class="language-plaintext highlighter-rouge">Inference Control</code>)í•˜ëŠ” ë°©ë²•ê¹Œì§€ ìµí˜”ë‹¤. ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì´ ëª¨ë¸ì„ ìš°ë¦¬ ë°ì´í„°ì— ë§ê²Œ íŠœë‹í•˜ëŠ” <strong>Training Loopì™€ Trainer API í™œìš©ë²•</strong>ì— ëŒ€í•´ ë‹¤ë£¨ê² ë‹¤.</p>]]></content><author><name></name></author><category term="engineering"/><category term="python"/><category term="transformers"/><category term="llm"/><category term="streaming"/><category term="inference"/><category term="backend"/><summary type="html"><![CDATA[í•˜ë“œì½”ë”©ëœ íŒŒë¼ë¯¸í„°ë¥¼ GenerationConfigë¡œ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬í•˜ëŠ” MLOps ë…¸í•˜ìš°ì™€ TextIteratorStreamerë¥¼ í™œìš©í•œ ChatGPT ìŠ¤íƒ€ì¼ì˜ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„ë²•.]]></summary></entry><entry><title type="html">[Transformers] OOM ì—†ëŠ” ì„¸ìƒ: ê±°ëŒ€ ëª¨ë¸ ë©”ëª¨ë¦¬ ì ì¬ ë° Offloading ì „ëµ</title><link href="https://ssolllll.github.io/blog/2025/offloading/" rel="alternate" type="text/html" title="[Transformers] OOM ì—†ëŠ” ì„¸ìƒ: ê±°ëŒ€ ëª¨ë¸ ë©”ëª¨ë¦¬ ì ì¬ ë° Offloading ì „ëµ"/><published>2025-12-07T10:00:00+00:00</published><updated>2025-12-07T10:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/offloading</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/offloading/"><![CDATA[<p>LLMì„ ë‹¤ë£¨ëŠ” ì—”ì§€ë‹ˆì–´ì—ê²Œ ê°€ì¥ ë‘ë ¤ìš´ ì—ëŸ¬ ë©”ì‹œì§€ëŠ” ë‹¨ì—° <code class="language-plaintext highlighter-rouge">CUDA out of memory</code>ì¼ ê²ƒì´ë‹¤. ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” 7B, 13Bë¥¼ ë„˜ì–´ 70B, 405Bë¡œ ì»¤ì ¸ê°€ëŠ”ë°, ìš°ë¦¬ê°€ ê°€ì§„ GPU VRAMì€ ì–¸ì œë‚˜ í•œì •ì ì´ë‹¤.</p> <p>ë‹¨ìˆœíˆ <code class="language-plaintext highlighter-rouge">.to("cuda")</code>ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ì€ ë”¥ëŸ¬ë‹ ì´ˆê¸°(BERT ì‹œì ˆ)ì˜ ìœ ì‚°ì´ë‹¤. ìˆ˜ì‹­ ê¸°ê°€ë°”ì´íŠ¸ì— ë‹¬í•˜ëŠ” LLMì„ ë¡œë”©í•  ë•ŒëŠ” <strong>Model Parallelism(ëª¨ë¸ ë³‘ë ¬í™”)</strong>ê³¼ <strong>Offloading(ì˜¤í”„ë¡œë”©)</strong> ê¸°ìˆ ì´ í•„ìˆ˜ì ì´ë‹¤.</p> <p>ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” <code class="language-plaintext highlighter-rouge">transformers</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì œê³µí•˜ëŠ” ìŠ¤ë§ˆíŠ¸í•œ ëª¨ë¸ ë¡œë”© ê¸°ë²•ë“¤ì„ ì •ë¦¬í•œë‹¤.</p> <hr/> <h2 id="1-precisionì •ë°€ë„-íƒ€í˜‘-fp32ì—ì„œ-fp16bf16ìœ¼ë¡œ">1. Precision(ì •ë°€ë„) íƒ€í˜‘: fp32ì—ì„œ fp16/bf16ìœ¼ë¡œ</h2> <p>ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(Weight)ë¥¼ ì–´ë–¤ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠëƒì— ë”°ë¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ì¦‰ì‹œ <strong>50%</strong> ì ˆê°ëœë‹¤.</p> <ul> <li><strong>float32 (Full Precision):</strong> íŒŒë¼ë¯¸í„°ë‹¹ 4 bytes. (ê¸°ë³¸ê°’)</li> <li><strong>float16 / bfloat16 (Half Precision):</strong> íŒŒë¼ë¯¸í„°ë‹¹ 2 bytes.</li> </ul> <h3 id="-bad-practice-ê¸°ë³¸-ë¡œë”©">ğŸ”´ Bad Practice: ê¸°ë³¸ ë¡œë”©</h3> <p>ì•„ë¬´ ì˜µì…˜ ì—†ì´ ëª¨ë¸ì„ ë¡œë“œí•˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ <code class="language-plaintext highlighter-rouge">float32</code>ë¡œ ë¡œë“œë˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. 7B ëª¨ë¸ ê¸°ì¤€ ì•½ <strong>28GB</strong>ì˜ VRAMì´ í•„ìš”í•˜ë‹¤. (7B * 4bytes)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># VRAM ë‚­ë¹„ì˜ ì£¼ë²”
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">meta-llama/Llama-2-7b-hf</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span> 
</code></pre></div></div> <h3 id="-best-practice-torch_dtype-ëª…ì‹œ">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">torch_dtype</code> ëª…ì‹œ</h3> <p><code class="language-plaintext highlighter-rouge">float16</code>ì„ ì‚¬ìš©í•˜ë©´ 7B ëª¨ë¸ì„ ì•½ <strong>14GB</strong>ì— ë¡œë“œí•  ìˆ˜ ìˆë‹¤. Ampere ì•„í‚¤í…ì²˜(A100, A10, RTX 30/40 ì‹œë¦¬ì¦ˆ) ì´ìƒì„ ì‚¬ìš©í•œë‹¤ë©´ <code class="language-plaintext highlighter-rouge">bfloat16</code>ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•™ìŠµ ì•ˆì •ì„± ë©´ì—ì„œ ë” ìœ ë¦¬í•˜ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">meta-llama/Llama-2-7b-hf</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span>  <span class="c1"># ë˜ëŠ” torch.float16
</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h2 id="2-model-offloading-gpuê°€-ë„˜ì¹˜ë©´-cpuë¡œ">2. Model Offloading: GPUê°€ ë„˜ì¹˜ë©´ CPUë¡œ</h2> <p>ëª¨ë¸ì´ GPU ë©”ëª¨ë¦¬ë³´ë‹¤ í´ ë•Œ, ê³¼ê±°ì—ëŠ” â€œì‹¤í–‰ ë¶ˆê°€â€ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ì œëŠ” <strong>Offloading</strong> ê¸°ìˆ ì„ í†µí•´ ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ CPU RAMì´ë‚˜ ë””ìŠ¤í¬ë¡œ ë‚´ë ¤ë³´ë‚´ê³ , ì¶”ë¡  ì‹œ í•„ìš”í•œ ë ˆì´ì–´ë§Œ GPUë¡œ ë¶ˆëŸ¬ì™€ ì—°ì‚°í•  ìˆ˜ ìˆë‹¤.</p> <h3 id="-best-practice-device_mapauto">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">device_map="auto"</code></h3> <p><code class="language-plaintext highlighter-rouge">accelerate</code> ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ì´ ì˜µì…˜ì€ ëª¨ë¸ì˜ ë ˆì´ì–´ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë°°ì¹˜ ì „ëµì„ ìë™ìœ¼ë¡œ ì§ ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">meta-llama/Llama-2-70b-hf</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span>  <span class="c1"># í•µì‹¬ ì˜µì…˜
</span><span class="p">)</span>

<span class="c1"># í˜„ì¬ ëª¨ë¸ì´ ì–´ë–»ê²Œ ë¶„ì‚°ë˜ì—ˆëŠ”ì§€ í™•ì¸
</span><span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">hf_device_map</span><span class="p">)</span>
<span class="c1"># ì¶œë ¥ ì˜ˆì‹œ:
# {
#   'model.embed_tokens': 0,        # GPU 0ë²ˆ
#   'model.layers.0': 0,
#   ...
#   'model.layers.40': 'cpu',       # GPU ê½‰ ì°¨ì„œ CPUë¡œ ì´ë™
#   'lm_head': 'disk'               # RAMë„ ë¶€ì¡±í•´ì„œ ë””ìŠ¤í¬ë¡œ ì´ë™
# }
</span></code></pre></div></div> <blockquote> <p><strong>Tip:</strong> ì¶”ë¡  ì†ë„ëŠ” ë‹¹ì—°íˆ ëŠë ¤ì§€ì§€ë§Œ(PCIe ëŒ€ì—­í­ ë³‘ëª©), <strong>â€œOOMìœ¼ë¡œ ì£½ëŠ” ê²ƒë³´ë‹¤ ëŠë¦¬ë”ë¼ë„ ëŒì•„ê°€ëŠ” ê²ƒì´ ë‚«ë‹¤â€</strong>ëŠ” ì—”ì§€ë‹ˆì–´ë§ ì›ì¹™ í•˜ì— ë§¤ìš° ìœ ìš©í•œ ì˜µì…˜ì´ë‹¤.</p> </blockquote> <hr/> <h2 id="3-max_memory-ì¶”ë¡ ì„-ìœ„í•œ-ì—¬ìœ -ê³µê°„-í™•ë³´">3. <code class="language-plaintext highlighter-rouge">max_memory</code>: ì¶”ë¡ ì„ ìœ„í•œ ì—¬ìœ  ê³µê°„ í™•ë³´</h2> <p><code class="language-plaintext highlighter-rouge">device_map="auto"</code>ëŠ” ê°€ëŠ¥í•œ í•œ GPU ë©”ëª¨ë¦¬ë¥¼ ê½‰ ì±„ì›Œì„œ ëª¨ë¸ì„ ì ì¬í•˜ë ¤ê³  í•œë‹¤. í•˜ì§€ë§Œ LLM ì¶”ë¡  ì‹œì—ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ ì™¸ì—ë„ <strong>KV Cache(Context ì €ì¥ì†Œ)</strong>ì™€ <strong>Activation</strong>ì„ ìœ„í•œ ë™ì  ë©”ëª¨ë¦¬ ê³µê°„ì´ í•„ìš”í•˜ë‹¤.</p> <p>VRAMì„ 100% ëª¨ë¸ ì ì¬ì— ì¨ë²„ë¦¬ë©´, ë§‰ìƒ ì¶”ë¡ ì„ ì‹œì‘í•˜ìë§ˆì OOMì´ ë°œìƒí•œë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ GPU ë©”ëª¨ë¦¬ ì‚¬ìš© í•œë„ë¥¼ ì œí•œí•´ì•¼ í•œë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GPU 0ë²ˆì€ 20GBê¹Œì§€ë§Œ ì“°ê³ , ë‚˜ë¨¸ì§€ëŠ” CPU(RAM) 100GBë¥¼ ì“°ê² ë‹¤.
</span><span class="n">max_memory_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="sh">"</span><span class="s">20GiB</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">100GiB</span><span class="sh">"</span><span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">meta-llama/Llama-2-13b-hf</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">max_memory</span><span class="o">=</span><span class="n">max_memory_mapping</span>
<span class="p">)</span>
</code></pre></div></div> <hr/> <h2 id="4-initialization-ìµœì í™”-low_cpu_mem_usage">4. Initialization ìµœì í™”: <code class="language-plaintext highlighter-rouge">low_cpu_mem_usage</code></h2> <p>PyTorchì˜ ì „í†µì ì¸ ëª¨ë¸ ë¡œë”© ë°©ì‹ì€ <strong>1) ëª¨ë¸ êµ¬ì¡°(ê»ë°ê¸°)ë¥¼ RAMì— ìƒì„±</strong>í•˜ê³  <strong>2) ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì½ì–´ì„œ ë®ì–´ì“°ëŠ”</strong> ë°©ì‹ì´ë‹¤. ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ í¬ê¸°ì˜ 2ë°°ì— ë‹¬í•˜ëŠ” ì‹œìŠ¤í…œ RAMì´ ìˆœê°„ì ìœ¼ë¡œ í•„ìš”í•˜ë‹¤. (RAM í­ë°œì˜ ì›ì¸)</p> <p>Hugging FaceëŠ” <strong>Meta Device</strong> ê¸°ìˆ ì„ í™œìš©í•˜ì—¬, ë¹ˆ ê»ë°ê¸°ë¥¼ ìƒì„±í•˜ì§€ ì•Šê³  ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ëŠ” <code class="language-plaintext highlighter-rouge">low_cpu_mem_usage=True</code> ì˜µì…˜ì„ ì œê³µí•œë‹¤. (<code class="language-plaintext highlighter-rouge">device_map="auto"</code> ì‚¬ìš© ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¼œì§)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ë•Œ
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">bigscience/bloom</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">low_cpu_mem_usage</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <hr/> <h2 id="ê²°ë¡ ">ê²°ë¡ </h2> <p>ê±°ëŒ€ ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” ê²ƒì€ â€œì–´ë–»ê²Œ í•˜ë©´ GPU VRAMì´ë¼ëŠ” ë¹„ì‹¼ ë¶€ë™ì‚°ì„ ì•Œëœ°í•˜ê²Œ ì“¸ ê²ƒì¸ê°€â€ì— ëŒ€í•œ ë¬¸ì œë‹¤.</p> <ol> <li><strong><code class="language-plaintext highlighter-rouge">torch_dtype</code></strong>: fp16/bf16ìœ¼ë¡œ ìš©ëŸ‰ì„ ì ˆë°˜ìœ¼ë¡œ ì¤„ì—¬ë¼.</li> <li><strong><code class="language-plaintext highlighter-rouge">device_map="auto"</code></strong>: GPU ìš©ëŸ‰ì´ ë¶€ì¡±í•˜ë©´ CPUì™€ Diskë¥¼ í™œìš©í•´ë¼.</li> <li><strong><code class="language-plaintext highlighter-rouge">max_memory</code></strong>: ì¶”ë¡  ì‹œ ìƒì„±ë  í† í°ì„ ìœ„í•´ VRAMì— ì—¬ìœ  ê³µê°„(Buffer)ì„ ë‚¨ê²¨ë‘¬ë¼.</li> </ol> <p>ì´ ì„¸ ê°€ì§€ë§Œ ê¸°ì–µí•´ë„ ë¡œì»¬ í™˜ê²½ì´ë‚˜ ì €ì‚¬ì–‘ ì„œë²„ì—ì„œ LLMì„ ì‹¤í—˜í•  ë•Œ ê²ªëŠ” ëŒ€ë¶€ë¶„ì˜ ë©”ëª¨ë¦¬ ë¬¸ì œëŠ” í•´ê²°ëœë‹¤. ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì´ë ‡ê²Œ ë¡œë“œí•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ <strong>ì‹¤ì œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ë•Œ(Inference)ì˜ ì œì–´ ê¸°ë²•</strong>ì— ëŒ€í•´ ì•Œì•„ë³´ê² ë‹¤.</p>]]></content><author><name></name></author><category term="engineering"/><category term="python"/><category term="transformers"/><category term="llm"/><category term="gpu"/><category term="memory"/><category term="optimization"/><summary type="html"><![CDATA[AutoModel ë¡œë”© ì‹œ ë°œìƒí•˜ëŠ” ë©”ëª¨ë¦¬ ë¶€ì¡±(OOM) í•´ê²°ë²•. device_mapì„ í™œìš©í•œ Offloading ì›ë¦¬ì™€ torch_dtype ì„¤ì •ì„ í†µí•œ VRAM ìµœì í™” ê°€ì´ë“œ.]]></summary></entry><entry><title type="html">[Python] collections ëª¨ë“ˆ ì‹¬ì¸µ ë¶„ì„</title><link href="https://ssolllll.github.io/blog/2025/python-package-collections/" rel="alternate" type="text/html" title="[Python] collections ëª¨ë“ˆ ì‹¬ì¸µ ë¶„ì„"/><published>2025-12-05T10:00:00+00:00</published><updated>2025-12-05T10:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/python-package-collections</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/python-package-collections/"><![CDATA[<p>LLM Model ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ë‹¤ ë³´ë©´ ëª¨ë¸ ìì²´ì˜ ì¶”ë¡  ì†ë„ë¿ë§Œ ì•„ë‹ˆë¼, ì „í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì˜ íš¨ìœ¨ì„±ì´ ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ëŠ” ê²½ìš°ë¥¼ ìì£¼ ë§ˆì£¼í•©ë‹ˆë‹¤.ã„´</p> <p>íŠ¹íˆ Pythonì˜ ê¸°ë³¸ ìë£Œêµ¬ì¡°(<code class="language-plaintext highlighter-rouge">list</code>, <code class="language-plaintext highlighter-rouge">dict</code>)ëŠ” ë²”ìš©ì ì´ì§€ë§Œ, <strong>ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ê°€ í•„ìš”í•œ Chat Completions API</strong>ë‚˜ <strong>ìˆ˜ì‹­ë§Œ ê°œì˜ Vector Search ê²°ê³¼ë¥¼ ë‹¤ë£¨ëŠ” RAG(Retrieval-Augmented Generation)</strong> ê³¼ì •ì—ì„œëŠ” ë¯¸ì„¸í•œ ì„±ëŠ¥ ì €í•˜ì™€ ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ì ìœ ì˜ ì›ì¸ì´ ë©ë‹ˆë‹¤.</p> <p><code class="language-plaintext highlighter-rouge">collections</code> ëª¨ë“ˆì„ ë‹¨ìˆœí•œ í¸ì˜ ë„êµ¬ê°€ ì•„ë‹Œ, <strong>ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì˜ ìµœì í™” ë„êµ¬</strong>ë¡œ ì¬í•´ì„í•˜ê³  LLM ì‹¤ë¬´ ì ìš© ì‚¬ë¡€ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.</p> <hr/> <h2 id="1-deque-context-window-ê´€ë¦¬ì™€-streaming-buffer">1. deque: Context Window ê´€ë¦¬ì™€ Streaming Buffer</h2> <p>LLMì€ ì…ë ¥ ê°€ëŠ¥í•œ í† í° ê¸¸ì´ì— ë¬¼ë¦¬ì  í•œê³„ê°€ ìˆë‹¤. ì±—ë´‡ êµ¬í˜„ ì‹œ ê°€ì¥ ì˜¤ë˜ëœ ëŒ€í™”ë¥¼ ì‚­ì œí•˜ê³  ìƒˆ ëŒ€í™”ë¥¼ ë„£ëŠ” <strong>Sliding Window</strong> ì „ëµì´ í•„ìˆ˜ì ì´ë‹¤. ë˜í•œ, SSE(Server-Sent Events) ìŠ¤íŠ¸ë¦¬ë° ì‹œ ë¬¸ì¥ ë‹¨ìœ„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë²„í¼ë§ì—ë„ í êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤.</p> <h3 id="-bad-practice-list-ì‚¬ìš©">ğŸ”´ Bad Practice: <code class="language-plaintext highlighter-rouge">list</code> ì‚¬ìš©</h3> <p>Pythonì˜ <code class="language-plaintext highlighter-rouge">list</code>ëŠ” ë™ì  ë°°ì—´(Dynamic Array)ì´ë‹¤. <code class="language-plaintext highlighter-rouge">pop(0)</code> ì—°ì‚°ì€ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì œê±°í•œ ë’¤, ë‚˜ë¨¸ì§€ <strong>ëª¨ë“  ìš”ì†Œì˜ ì¸ë±ìŠ¤ë¥¼ í•œ ì¹¸ì”© ë‹¹ê²¨ì˜¤ëŠ”(Shift)</strong> ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p> <ul> <li><strong>ì‹œê°„ ë³µì¡ë„:</strong> $O(N)$</li> <li><strong>ë¬¸ì œì :</strong> ëŒ€í™” í„´(Turn)ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡, ë™ì‹œ ì ‘ì†ìê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ CPU ì‚¬ì´í´ì„ ë‚­ë¹„í•˜ë©°, GC(Garbage Collection) ì••ë ¥ì„ ë†’ì¸ë‹¤.</li> </ul> <h3 id="-best-practice-deque-circular-buffer">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">deque</code> (Circular Buffer)</h3> <p><code class="language-plaintext highlighter-rouge">collections.deque</code>ëŠ” Linked List ê¸°ë°˜ì˜ ì–‘ë°©í–¥ íë‹¤. ì–‘ ëë‹¨ì—ì„œì˜ ì‚½ì…/ì‚­ì œê°€ ë©”ëª¨ë¦¬ ì´ë™ ì—†ì´ í¬ì¸í„° ë³€ê²½ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤.</p> <p><img src="/assets/img/deque_vs_list_memory.png" alt="Deque vs List Memory Structure"/></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>

<span class="k">class</span> <span class="nc">ContextManager</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max_turns</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="c1"># maxlenì„ ì§€ì •í•˜ë©´ ê½‰ ì°¼ì„ ë•Œ append ì‹œ 
</span>        <span class="c1"># ìë™ìœ¼ë¡œ ë°˜ëŒ€í¸ ë°ì´í„°ê°€ O(1)ë¡œ ì‚­ì œë¨ (Memory Allocation ë°œìƒ ì•ˆ í•¨)
</span>        <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">max_turns</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_dialogue</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">assistant</span><span class="p">):</span>
        <span class="c1"># íŠœí”Œë¡œ ì €ì¥í•˜ì—¬ ë¶ˆë³€ì„±(Immutability) ë³´ì¥ ë° ë©”ëª¨ë¦¬ ì ˆì•½
</span>        <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="n">user</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span> <span class="n">assistant</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_prompt_context</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># LLM API ìš”ì²­ ì§ì „ì—ë§Œ listë¡œ ë³€í™˜ (ë³€í™˜ ë¹„ìš©ì€ ë¬´ì‹œí•  ìˆ˜ì¤€)
</span>        <span class="k">return</span> <span class="p">[{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="n">r</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">c</span><span class="p">}</span> <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span><span class="p">]</span>
</code></pre></div></div> <blockquote> <p><strong>Key Engineering Point:</strong> <code class="language-plaintext highlighter-rouge">maxlen</code>ì„ ì„¤ì •í•œ <code class="language-plaintext highlighter-rouge">deque</code>ëŠ” ë§ ë²„í¼(Ring Buffer)ì²˜ëŸ¼ ë™ì‘í•˜ì—¬, ì˜¤ë˜ëœ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ëŠ” ì½”ë“œë¥¼ ë³„ë„ë¡œ ì‘ì„±í•  í•„ìš”ê°€ ì—†ì–´ ì½”ë“œê°€ ê°„ê²°í•´ì§€ê³  ì‹¤ìˆ˜ê°€ ì¤„ì–´ë“ ë‹¤.</p> </blockquote> <hr/> <h2 id="2-namedtuple-ëŒ€ê·œëª¨-vector-search-ê²°ê³¼ì˜-ë©”ëª¨ë¦¬-ê²½ëŸ‰í™”">2. namedtuple: ëŒ€ê·œëª¨ Vector Search ê²°ê³¼ì˜ ë©”ëª¨ë¦¬ ê²½ëŸ‰í™”</h2> <p>RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±) ì‹œìŠ¤í…œì—ì„œëŠ” Vector DBë¡œë¶€í„° ìˆ˜ì²œ ê°œì˜ ì²­í¬(Chunk)ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ Reranking í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹œë‹¤. ì´ë•Œ ê° ê²€ìƒ‰ ê²°ê³¼ë¥¼ <code class="language-plaintext highlighter-rouge">dict</code>ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì€ ë©”ëª¨ë¦¬ ë¹„íš¨ìœ¨ì ì´ë‹¤.</p> <h3 id="-bad-practice-dict-ë¦¬ìŠ¤íŠ¸-ì‚¬ìš©">ğŸ”´ Bad Practice: <code class="language-plaintext highlighter-rouge">dict</code> ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©</h3> <p>Pythonì˜ <code class="language-plaintext highlighter-rouge">dict</code>ëŠ” í•´ì‹œ í…Œì´ë¸” êµ¬ì¡°ë¡œ, ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ Key ê°’ ìì²´ì™€ í•´ì‹œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ê³µê°„ì„ ì ìœ í•œë‹¤. ê°ì²´ í•˜ë‚˜ë‹¹ ì˜¤ë²„í—¤ë“œê°€ í¬ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ì¼ë°˜ì ì¸ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°
</span><span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">doc_1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">score</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.89</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">...</span><span class="sh">"</span><span class="p">}</span> 
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># ìˆ˜ë§Œ ê±´ì˜ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸‰ì¦
</span></code></pre></div></div> <h3 id="-best-practice-namedtuple-í™œìš©">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">namedtuple</code> í™œìš©</h3> <p><code class="language-plaintext highlighter-rouge">collections.namedtuple</code>ì€ ë‚´ë¶€ì ìœ¼ë¡œ íŠœí”Œ(Tuple) êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë˜, í•„ë“œëª…ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤. <code class="language-plaintext highlighter-rouge">__dict__</code> ì†ì„±ì„ ê°€ì§€ì§€ ì•Šì•„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í˜„ì €íˆ ì ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">import</span> <span class="n">sys</span>

<span class="c1"># ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°ì²´ ì •ì˜
</span><span class="n">SearchResult</span> <span class="o">=</span> <span class="nf">namedtuple</span><span class="p">(</span><span class="sh">"</span><span class="s">SearchResult</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">score</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ ì‹¤í—˜
</span><span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">id</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">score</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">A</span><span class="sh">"</span><span class="p">}</span>
<span class="n">n</span> <span class="o">=</span> <span class="nc">SearchResult</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="sh">"</span><span class="s">1</span><span class="sh">"</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="sh">"</span><span class="s">A</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Dict Size: </span><span class="si">{</span><span class="n">sys</span><span class="p">.</span><span class="nf">getsizeof</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes</span><span class="sh">"</span><span class="p">)</span>       <span class="c1"># ì˜ˆ: 232 bytes
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">NamedTuple Size: </span><span class="si">{</span><span class="n">sys</span><span class="p">.</span><span class="nf">getsizeof</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># ì˜ˆ: 72 bytes
# -&gt; ì•½ 3ë°° ì´ìƒì˜ ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼
</span></code></pre></div></div> <p><strong>ì ìš© ì‹œë‚˜ë¦¬ì˜¤:</strong></p> <ul> <li>Vector DBì—ì„œ ê°€ì ¸ì˜¨ 1ì°¨ í›„ë³´êµ°(Top-K 100~1000ê°œ)ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦´ ë•Œ.</li> <li>Reranker ëª¨ë¸ì— ë°°ì¹˜(Batch)ë¡œ ë°ì´í„°ë¥¼ ë„˜ê¸°ê¸° ì „ ì „ì²˜ë¦¬ ê³¼ì •.</li> </ul> <hr/> <h2 id="3-defaultdict-ë¬¸ì„œ-ì²­í¬chunk-ê·¸ë£¹í•‘-ê°€ì†í™”">3. defaultdict: ë¬¸ì„œ ì²­í¬(Chunk) ê·¸ë£¹í•‘ ê°€ì†í™”</h2> <p>ê¸´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ, ì—¬ëŸ¬ ê°œì˜ ì²­í¬ë¡œ ë‚˜ë‰˜ì–´ ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì›ë³¸ ë¬¸ì„œ ID ê¸°ì¤€ìœ¼ë¡œ í•©ì³ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤(Map-Reduce íŒ¨í„´).</p> <h3 id="-bad-practice-if-key-in-dict-ì²´í¬">ğŸ”´ Bad Practice: <code class="language-plaintext highlighter-rouge">if key in dict</code> ì²´í¬</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunk_results</span><span class="p">:</span>
    <span class="n">doc_id</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[</span><span class="sh">'</span><span class="s">doc_id</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">doc_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="n">results</span><span class="p">[</span><span class="n">doc_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">results</span><span class="p">[</span><span class="n">doc_id</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div> <p>ì´ ë°©ì‹ì€ ë§¤ ë°˜ë³µë§ˆë‹¤ Key ì¡´ì¬ ì—¬ë¶€ë¥¼ í•´ì‹±í•˜ì—¬ ê²€ì‚¬í•˜ë¯€ë¡œ ë¶ˆí•„ìš”í•œ ì—°ì‚°ì´ í¬í•¨ëœë‹¤.</p> <h3 id="-best-practice-defaultdict">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">defaultdict</code></h3> <p><code class="language-plaintext highlighter-rouge">collections.defaultdict</code>ëŠ” Keyê°€ ì—†ì„ ë•Œì˜ ì´ˆê¸°í™” ë¡œì§ì„ C ë ˆë²¨ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ, Python ë ˆë²¨ì˜ ë¶„ê¸°ë¬¸(Branching)ì„ ì œê±°í•˜ì—¬ ë£¨í”„ ì†ë„ë¥¼ ë†’ì¸ë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="c1"># ì›ë³¸ ë¬¸ì„œ IDë³„ë¡œ ìš”ì•½ë³¸ì„ ëª¨ìœ¼ëŠ” íŒŒì´í”„ë¼ì¸
</span><span class="n">aggregated_data</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunk_results</span><span class="p">:</span>
    <span class="c1"># Key ê²€ì‚¬ ë¡œì§ ì‚­ì œ -&gt; ì½”ë“œ ê°€ë…ì„± í–¥ìƒ ë° ì†ë„ ìµœì í™”
</span>    <span class="n">aggregated_data</span><span class="p">[</span><span class="n">chunk</span><span class="p">[</span><span class="sh">'</span><span class="s">doc_id</span><span class="sh">'</span><span class="p">]].</span><span class="nf">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div> <hr/> <h2 id="4-chainmap-llm-í•˜ì´í¼íŒŒë¼ë¯¸í„°-ê³„ì¸µ-ê´€ë¦¬">4. ChainMap: LLM í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³„ì¸µ ê´€ë¦¬</h2> <p>LLM ì¶”ë¡  ì‹œ <code class="language-plaintext highlighter-rouge">Temperature</code>, <code class="language-plaintext highlighter-rouge">Top_p</code>, <code class="language-plaintext highlighter-rouge">Max_tokens</code> ë“±ì˜ ì„¤ì •ì€ <strong>[ê¸°ë³¸ ì„¤ì •] -&gt; [ìœ ì € ì„¤ì •] -&gt; [í”„ë¡¬í”„íŠ¸ë³„ ì„ì‹œ ì„¤ì •]</strong> ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì§„ë‹¤. ì´ë¥¼ <code class="language-plaintext highlighter-rouge">dict.update()</code>ë¡œ ë§¤ë²ˆ ìƒˆë¡œìš´ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ë³‘í•©í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë‹¤.</p> <h3 id="-best-practice-chainmap">ğŸŸ¢ Best Practice: <code class="language-plaintext highlighter-rouge">ChainMap</code></h3> <p><code class="language-plaintext highlighter-rouge">collections.ChainMap</code>ì€ ì—¬ëŸ¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‹¤ì œë¡œ ë³‘í•©(Copy)í•˜ì§€ ì•Šê³ , ì—°ê²°ëœ ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ ë…¼ë¦¬ì ìœ¼ë¡œë§Œ ë³‘í•©í•˜ì—¬ ë³´ì—¬ì¤€ë‹¤. ì¡°íšŒ ì‹œ ì•ìª½ ë”•ì…”ë„ˆë¦¬ë¶€í„° íƒìƒ‰í•œë‹¤.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">ChainMap</span>

<span class="n">default_config</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">temperature</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span> <span class="sh">"</span><span class="s">max_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="sh">"</span><span class="s">top_p</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">}</span>
<span class="n">user_config</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">temperature</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>  <span class="c1"># ìœ ì €ê°€ ì˜¨ë„ë¥¼ ë‚®ì¶¤
</span><span class="n">request_override</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">max_tokens</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1024</span><span class="p">}</span> <span class="c1"># ì´ë²ˆ ìš”ì²­ë§Œ ê¸¸ê²Œ
</span>
<span class="c1"># ìƒˆë¡œìš´ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì—†ì´ ë…¼ë¦¬ì  ë·°ë§Œ ìƒì„± (Zero-copy)
</span><span class="n">final_config</span> <span class="o">=</span> <span class="nc">ChainMap</span><span class="p">(</span><span class="n">request_override</span><span class="p">,</span> <span class="n">user_config</span><span class="p">,</span> <span class="n">default_config</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">final_config</span><span class="p">[</span><span class="sh">'</span><span class="s">temperature</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># 0.5 (user_config ì ìš©)
</span><span class="nf">print</span><span class="p">(</span><span class="n">final_config</span><span class="p">[</span><span class="sh">'</span><span class="s">max_tokens</span><span class="sh">'</span><span class="p">])</span>  <span class="c1"># 1024 (request_override ì ìš©)
</span><span class="nf">print</span><span class="p">(</span><span class="n">final_config</span><span class="p">[</span><span class="sh">'</span><span class="s">top_p</span><span class="sh">'</span><span class="p">])</span>       <span class="c1"># 0.9 (default_config ì ìš©)
</span></code></pre></div></div> <p>ì´ ë°©ì‹ì€ ìš”ì²­ë§ˆë‹¤ ê±°ëŒ€í•œ ì„¤ì • ê°ì²´ë¥¼ ë³µì‚¬í•  í•„ìš”ê°€ ì—†ì–´ <strong>High-Throughput API ì„œë²„</strong>ì—ì„œ GC ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•œë‹¤.</p> <hr/> <h2 id="ê²°ë¡ -micro-optimizationì´-ëª¨ì—¬-ì‹œìŠ¤í…œ-ì•ˆì •ì„±ì„-ë§Œë“ ë‹¤">ê²°ë¡ : Micro-Optimizationì´ ëª¨ì—¬ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ë§Œë“ ë‹¤</h2> <p>Pythonì€ ëŠë¦¬ë‹¤ëŠ” í¸ê²¬ì´ ìˆì§€ë§Œ, ë‚´ì¥ëœ <code class="language-plaintext highlighter-rouge">collections</code> ëª¨ë“ˆì„ ì ì¬ì ì†Œì— í™œìš©í•˜ë©´ Cë¡œ êµ¬í˜„ëœ ë‚´ë¶€ ìµœì í™”ì˜ í˜œíƒì„ ê·¸ëŒ€ë¡œ ëˆ„ë¦´ ìˆ˜ ìˆë‹¤.</p> <ul> <li><strong>Queueing/History:</strong> <code class="language-plaintext highlighter-rouge">deque</code></li> <li><strong>Data Object:</strong> <code class="language-plaintext highlighter-rouge">namedtuple</code></li> <li><strong>Grouping:</strong> <code class="language-plaintext highlighter-rouge">defaultdict</code></li> <li><strong>Config Merging:</strong> <code class="language-plaintext highlighter-rouge">ChainMap</code></li> </ul> <p>LLM ì„œë¹„ìŠ¤ëŠ” í…ìŠ¤íŠ¸ë¼ëŠ” ë¹„ì •í˜• ë°ì´í„°ë¥¼ ëŒ€ëŸ‰ìœ¼ë¡œ ë‹¤ë£¨ëŠ” ë§Œí¼, ì´ëŸ¬í•œ ìë£Œêµ¬ì¡°ì˜ ì„ íƒì´ <strong>Latency(ì§€ì—° ì‹œê°„)</strong>ì™€ <strong>Memory Footprint(ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰)</strong>ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ìƒê°ë³´ë‹¤ í¬ë‹¤. í™”ë ¤í•œ ëª¨ë¸ íŠœë‹ ì´ì „ì—, ê²¬ê³ í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì´ ì„ í–‰ë˜ì–´ì•¼ í•¨ì„ ìŠì§€ ë§ì.</p>]]></content><author><name></name></author><category term="engineering"/><category term="python"/><category term="llm"/><category term="optimization"/><category term="backend"/><summary type="html"><![CDATA[ë‹¨ìˆœí•œ ë¬¸ë²• ì†Œê°œê°€ ì•„ë‹Œ, ë‚˜ì—ê²Œ ìˆì–´ í•„ìš”í•œ collections ëª¨ë“ˆ ë¶„ì„.]]></summary></entry><entry><title type="html">a post with plotly.js</title><link href="https://ssolllll.github.io/blog/2025/plotly/" rel="alternate" type="text/html" title="a post with plotly.js"/><published>2025-03-26T14:24:00+00:00</published><updated>2025-03-26T14:24:00+00:00</updated><id>https://ssolllll.github.io/blog/2025/plotly</id><content type="html" xml:base="https://ssolllll.github.io/blog/2025/plotly/"><![CDATA[<p>This is an example post with some <a href="https://plotly.com/javascript/">plotly</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included plotly.js code could look like]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://ssolllll.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://ssolllll.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://ssolllll.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://ssolllll.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://ssolllll.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://ssolllll.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024 Weâ€™re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, weâ€™re introducing Gemini 1.5 Flash: a model thatâ€™s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.Weâ€™re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5â€™s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. Itâ€™s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While itâ€™s a lighter weight model than 1.5 Pro, itâ€™s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because itâ€™s been trained by 1.5 Pro through a process called â€œdistillation,â€ where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flashâ€™s availability and pricing.Over the last few months, weâ€™ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, weâ€™ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. Weâ€™ve improved control over the modelâ€™s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And weâ€™ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And weâ€™re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do â€” not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, weâ€™re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.Weâ€™re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And weâ€™ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMindâ€™s mission to build AI responsibly to benefit humanity, weâ€™ve always wanted to develop universal AI agents that can be helpful in everyday life. Thatâ€™s why today, weâ€™re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do â€” and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While weâ€™ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, weâ€™ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, weâ€™ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context theyâ€™re being used in, and respond quickly, in conversation.With technology like this, itâ€™s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.Weâ€™ve made incredible progress so far with our family of Gemini models, and weâ€™re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, weâ€™re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Googleâ€™s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Letâ€™s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[Weâ€™re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://ssolllll.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://ssolllll.github.io/blog/2024/tabs</id><content type="html" xml:base="https://ssolllll.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="d5908f24-88fe-4310-9623-3006595f1581" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="d5908f24-88fe-4310-9623-3006595f1581" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="616f07ac-5307-48e5-b561-b8624fd149bb" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="616f07ac-5307-48e5-b561-b8624fd149bb" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="3fa4b0c2-8463-4f44-8d1c-733dd199bac6" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="3fa4b0c2-8463-4f44-8d1c-733dd199bac6" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry></feed>