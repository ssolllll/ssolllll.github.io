---
layout: post
title: "[Transformers] íŒŒì´í† ì¹˜ ë£¨í”„ íƒˆì¶œ: Trainer API 200% í™œìš© ê°€ì´ë“œ"
date: 2025-12-13 10:00:00
description: Raw PyTorch Loop ëŒ€ì‹  Trainerë¥¼ ì¨ì•¼ í•˜ëŠ” ì´ìœ . Custom Callbackì„ ì´ìš©í•œ ì‹¤ì‹œê°„ ìƒì„± í‰ê°€ì™€ íš¨ìœ¨ì ì¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì „ëµ.
tags: python transformers training mlops backend
categories: engineering
---

ë”¥ëŸ¬ë‹ ëª¨ë¸ë§ì„ ì²˜ìŒ ë°°ìš¸ ë•ŒëŠ” `for epoch in epochs:` ë¡œ ì‹œì‘í•˜ëŠ” PyTorchì˜ Raw Loopë¥¼ ì§ì ‘ ì§œëŠ” ê²ƒì´ ê³µë¶€ì— ë„ì›€ì´ ëœë‹¤. 
í•˜ì§€ë§Œ **ìƒìš© ìˆ˜ì¤€ì˜ LLM í•™ìŠµ íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•  ë•Œ ì´ ë°©ì‹ì€ 'ê¸°ìˆ  ë¶€ì±„(Technical Debt)'ê°€ ë˜ê¸° ì‰½ë‹¤.

Mixed Precision(fp16), Gradient Accumulation, Multi-GPU ë¶„ì‚° í•™ìŠµ(DDP), Logging, Checkpointing ê¸°ëŠ¥ì„ ë§¤ë²ˆ ì§ì ‘ êµ¬í˜„í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë‹¤.

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” Hugging Faceì˜ `Trainer` APIë¥¼ ë‹¨ìˆœí•œ í¸ì˜ ë„êµ¬ê°€ ì•„ë‹Œ, **ê²¬ê³ í•œ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì˜ í‘œì¤€ ê·œê²©**ìœ¼ë¡œ í™œìš©í•˜ëŠ” ì—”ì§€ë‹ˆì–´ë§ íŒì„ ê³µìœ í•œë‹¤.

---

## 1. Trainer: Boilerplate Code ì œê±°ì™€ í‘œì¤€í™”

`Trainer` í´ë˜ìŠ¤ëŠ” í•™ìŠµì— í•„ìš”í•œ ëª¨ë“  Best Practiceê°€ ì§‘ì•½ë˜ì–´ ìˆë‹¤. 

### ğŸ”´ Bad Practice: Raw PyTorch Loop
```python
# ë§¤ í”„ë¡œì íŠ¸ë§ˆë‹¤ ë°˜ë³µë˜ëŠ” ì§€ë£¨í•œ ì½”ë“œ...
scaler = torch.cuda.amp.GradScaler()
for batch in dataloader:
    optimizer.zero_grad()
    outputs = model(**batch)
    loss = outputs.loss
    scaler.scale(loss).backward()  # fp16 ì²˜ë¦¬
    
    if step % accumulation_steps == 0: # ê·¸ë¼ë””ì–¸íŠ¸ ëˆ„ì  ì²˜ë¦¬
        scaler.step(optimizer)
        scaler.update()
    
    # ë¡œê¹…, ì²´í¬í¬ì¸íŠ¸ ì €ì¥, ê²€ì¦ ë¡œì§ ë“± ìˆ˜ë°± ì¤„ ì¶”ê°€ í•„ìš”
```

### ğŸŸ¢ Best Practice: TrainingArguments í™œìš©
`TrainingArguments`ì— ì„¤ì •ê°’ë§Œ ë„˜ê¸°ë©´ ë³µì¡í•œ ê¸°ëŠ¥ë“¤ì´ ë‚´ë¶€ì ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ì‹¤í–‰ëœë‹¤.

```python
from transformers import TrainingArguments, Trainer

args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4, # ë°°ì¹˜ í¬ê¸° 16 íš¨ê³¼
    fp16=True,                     # Mixed Precision ìë™ ì ìš©
    logging_steps=100,
    report_to="wandb",             # WandB, MLflow ìë™ ì—°ë™
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    # ...
)
```

> **Engineering Note:** íŒ€ ë‚´ì—ì„œ `TrainingArguments` ì„¤ì •ì„ ê³µìœ í•˜ë©´, ëˆ„ê°€ í•™ìŠµ ì½”ë“œë¥¼ ì§œë”ë¼ë„ ë™ì¼í•œ ë¡œê¹… í¬ë§·ê³¼ ì €ì¥ êµ¬ì¡°ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆì–´ í˜‘ì—… íš¨ìœ¨ì´ ê·¹ëŒ€í™”ëœë‹¤.

---

## 2. Callback: í•™ìŠµ ì¤‘ê°„ì— ê°œì…í•˜ê¸° (Hooking)

`Trainer`ë¥¼ ì“°ë©´ ë‚´ë¶€ ë¡œì§ì„ ìˆ˜ì •í•˜ê¸° ì–´ë µë‹¤ê³  ìƒê°í•˜ê¸° ì‰½ë‹¤. í•˜ì§€ë§Œ `TrainerCallback`ì„ ì‚¬ìš©í•˜ë©´ **í•™ìŠµì˜ íŠ¹ì • ì‹œì (Start, Step End, Epoch End ë“±)**ì— ì›í•˜ëŠ” ì½”ë“œë¥¼ ì£¼ì…(Hook)í•  ìˆ˜ ìˆë‹¤.

LLM í•™ìŠµ ì‹œ ê°€ì¥ ìœ ìš©í•œ ê²ƒì€ **"Lossë§Œ ë³´ì§€ ë§ê³ , ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì˜ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒ"**ì´ë‹¤.



### ğŸŸ¢ Best Practice: ì‹¤ì‹œê°„ ìƒì„± í‰ê°€ Callback
í•™ìŠµ ë„ì¤‘(ì˜ˆ: ë§¤ 500 step ë§ˆë‹¤) ëª¨ë¸ì´ ë©ì²­í•œ ì†Œë¦¬ë¥¼ í•˜ê³  ìˆì§„ ì•Šì€ì§€ ìƒ˜í”Œì„ ìƒì„±í•´ì„œ ë¡œê·¸ì— ì°ì–´ë³´ëŠ” ì½œë°±ì´ë‹¤.

```python
from transformers import TrainerCallback

class GenerationCallback(TrainerCallback):
    def __init__(self, tokenizer, prompt_text="User: ì•ˆë…•?\nAssistant:"):
        self.tokenizer = tokenizer
        self.prompt_text = prompt_text

    def on_step_end(self, args, state, control, model=None, **kwargs):
        # 500 ìŠ¤í…ë§ˆë‹¤ ì‹¤í–‰
        if state.global_step % 500 == 0:
            inputs = self.tokenizer(self.prompt_text, return_tensors="pt").to(model.device)
            
            # í•™ìŠµ ëª¨ë“œ(train) -> í‰ê°€ ëª¨ë“œ(eval)ë¡œ ì ì‹œ ì „í™˜
            model.eval()
            with torch.no_grad():
                outputs = model.generate(**inputs, max_new_tokens=50)
                generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            print(f"\n[Step {state.global_step}] Sample:\n{generated_text}\n")
            
            # ë‹¤ì‹œ í•™ìŠµ ëª¨ë“œë¡œ ë³µê·€
            model.train()

# Trainerì— ë“±ë¡
trainer = Trainer(
    ...,
    callbacks=[GenerationCallback(tokenizer)]
)
```

ì´ ì½œë°±ì´ ìˆìœ¼ë©´ í•™ìŠµì´ ì‚°ìœ¼ë¡œ ê°€ê³  ìˆëŠ”ì§€(Overfitting/Collapse)ë¥¼ Loss ê·¸ë˜í”„ë³´ë‹¤ í›¨ì”¬ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.

---

## 3. Storage Management: ë””ìŠ¤í¬ í­ë°œ ë°©ì§€

LLM ì²´í¬í¬ì¸íŠ¸(Checkpoint)ëŠ” ê°œë‹¹ ìˆ˜ì‹­ GBì— ë‹¬í•œë‹¤. ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë‘ë©´ ë§¤ `save_steps` ë§ˆë‹¤ ì €ì¥ì´ ë˜ì–´ ê¸ˆì„¸ ë””ìŠ¤í¬ê°€ ê°€ë“ ì°¬ë‹¤.

### ğŸŸ¢ Best Practice: `save_total_limit` & `load_best_model_at_end`

ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ í•˜ë‚˜ì™€, í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë‹¨ì„ ëŒ€ë¹„í•œ ìµœì‹  ëª¨ë¸ í•˜ë‚˜ë§Œ ë‚¨ê¸°ëŠ” ì „ëµì´ë‹¤.

```python
args = TrainingArguments(
    output_dir="./llm-checkpoints",
    save_strategy="steps",
    save_steps=1000,
    evaluation_strategy="steps",
    eval_steps=1000,
    
    # í•µì‹¬ ì˜µì…˜:
    save_total_limit=2,          # ê°€ì¥ ìµœê·¼ 2ê°œë§Œ ë‚¨ê¸°ê³  ìë™ ì‚­ì œ
    load_best_model_at_end=True, # í•™ìŠµ ì¢…ë£Œ ì‹œ validation lossê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸ ë¡œë“œ
    metric_for_best_model="loss"
)
```

ì´ ì„¤ì •ì„ í†µí•´ ë””ìŠ¤í¬ ìš©ëŸ‰ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ë©´ì„œë„, í•™ìŠµì´ ì¤‘ê°„ì— ë©ˆì·„ì„ ë•Œ `trainer.train(resume_from_checkpoint=True)`ë¥¼ í†µí•´ ì–¸ì œë“  ì¬ê°œí•  ìˆ˜ ìˆëŠ” ì•ˆì „ì¥ì¹˜ë¥¼ ë§ˆë ¨í•  ìˆ˜ ìˆë‹¤.

---

## ê²°ë¡ 

`Trainer` APIë¥¼ ì˜ ì“´ë‹¤ëŠ” ê²ƒì€ ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ë„˜ì–´, **ì‹¤í—˜ì˜ ì¬í˜„ì„±(Reproducibility)**ê³¼ **ìš´ì˜ì˜ ì•ˆì •ì„±(Stability)**ì„ í™•ë³´í•œë‹¤ëŠ” ì˜ë¯¸ë‹¤.

1.  **Arguments:** ë³µì¡í•œ í•™ìŠµ ì„¤ì •ì„ dataclass í•˜ë‚˜ë¡œ ê´€ë¦¬.
2.  **Callback:** í•™ìŠµ ê³¼ì •ì— ìœ ì—°í•˜ê²Œ ê°œì…í•˜ì—¬ Custom Logic ì‹¤í–‰.
3.  **Checkpointing:** ë””ìŠ¤í¬ ìš©ëŸ‰ ê´€ë¦¬ ìë™í™”.

ì´ì œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” íŒŒì´í”„ë¼ì¸ê¹Œì§€ êµ¬ì¶•í–ˆë‹¤. ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” í•™ìŠµëœ ê±°ëŒ€ ëª¨ë¸ì„ ë” ì‘ê³  ë¹ ë¥´ê²Œ ë§Œë“œëŠ” **"5. Optimization: ì–‘ìí™”(Quantization)ì™€ íš¨ìœ¨í™” ê¸°ë²•"**ì´ë‹¤. ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ ì‹œë¦¬ì¦ˆë¥¼ ë§ˆë¬´ë¦¬í•´ë³´ì.